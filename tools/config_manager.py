#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Configuration Manager CLI
çµ±ä¸€ç®¡ç†sales assistanté…ç½®æª”æ¡ˆçš„å‘½ä»¤åˆ—å·¥å…·
"""

import os
import sys
import json
import argparse
from pathlib import Path
from tabulate import tabulate
from typing import Dict, Any, List
import subprocess

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# è¨­å®šæª”è·¯å¾‘
ENTITY_PATTERNS_PATH = project_root / "libs/services/sales_assistant/prompts/entity_patterns.json"
QUERY_KEYWORDS_PATH = project_root / "libs/services/sales_assistant/prompts/query_keywords.json"
BACKUP_DIR = project_root / "tools/backups"

class ConfigManager:
    """çµ±ä¸€é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.backup_dir = BACKUP_DIR
        self.backup_dir.mkdir(exist_ok=True)
        
        self.config_files = {
            'entity_patterns': ENTITY_PATTERNS_PATH,
            'query_keywords': QUERY_KEYWORDS_PATH
        }
    
    def _load_config(self, config_type: str) -> Dict[str, Any]:
        """è¼‰å…¥æŒ‡å®šé¡å‹çš„é…ç½®"""
        if config_type not in self.config_files:
            return {}
        
        try:
            with open(self.config_files[config_type], 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¼‰å…¥ {config_type} é…ç½®å¤±æ•—: {e}")
            return {}
    
    def status(self):
        """é¡¯ç¤ºé…ç½®æª”æ¡ˆç‹€æ…‹"""
        print("ğŸ” Sales Assistant é…ç½®æª”æ¡ˆç‹€æ…‹:\n")
        
        table_data = []
        for config_name, config_path in self.config_files.items():
            if config_path.exists():
                try:
                    data = self._load_config(config_name)
                    size = config_path.stat().st_size
                    
                    if config_name == 'entity_patterns':
                        entity_count = len(data.get('entity_patterns', {}))
                        status = f"âœ… {entity_count} å€‹å¯¦é«”é¡å‹"
                    elif config_name == 'query_keywords':
                        intent_count = len(data.get('intent_keywords', {}))
                        status = f"âœ… {intent_count} å€‹æ„åœ–"
                    else:
                        status = "âœ… å­˜åœ¨"
                    
                    table_data.append([
                        config_name,
                        str(config_path),
                        f"{size} bytes",
                        status
                    ])
                except Exception as e:
                    table_data.append([
                        config_name,
                        str(config_path),
                        "éŒ¯èª¤",
                        f"âŒ {str(e)[:50]}..."
                    ])
            else:
                table_data.append([
                    config_name,
                    str(config_path),
                    "ä¸å­˜åœ¨",
                    "âŒ æª”æ¡ˆä¸å­˜åœ¨"
                ])
        
        headers = ['é…ç½®é¡å‹', 'æª”æ¡ˆè·¯å¾‘', 'å¤§å°', 'ç‹€æ…‹']
        print(tabulate(table_data, headers=headers, tablefmt='grid'))
    
    def sync_modeltypes(self):
        """åŒæ­¥æ•¸æ“šåº«ä¸­çš„modeltypeåˆ°é…ç½®æª”æ¡ˆ"""
        print("ğŸ”„ åŒæ­¥æ•¸æ“šåº«ä¸­çš„modeltypeåˆ°é…ç½®æª”æ¡ˆ...")
        
        try:
            # å¾æ•¸æ“šåº«ç²å–modeltype
            from config import DB_PATH
            import duckdb
            
            conn = duckdb.connect(str(DB_PATH))
            result = conn.execute('SELECT DISTINCT modeltype FROM specs ORDER BY modeltype').fetchall()
            conn.close()
            
            modeltypes = [row[0] for row in result]
            print(f"ğŸ“‹ å¾æ•¸æ“šåº«ç²å–åˆ°çš„modeltype: {modeltypes}")
            
            # æ›´æ–°entity_patterns.json
            entity_data = self._load_config('entity_patterns')
            if 'entity_patterns' in entity_data and 'MODEL_TYPE' in entity_data['entity_patterns']:
                # æ§‹å»ºæ–°çš„pattern
                pattern = f"\\\\b(?:{'|'.join(modeltypes)})\\\\b"
                entity_data['entity_patterns']['MODEL_TYPE']['patterns'] = [pattern]
                entity_data['entity_patterns']['MODEL_TYPE']['examples'] = modeltypes
                
                # å„²å­˜æ›´æ–°
                self._create_backup('entity_patterns')
                with open(ENTITY_PATTERNS_PATH, 'w', encoding='utf-8') as f:
                    json.dump(entity_data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… å·²æ›´æ–° entity_patterns.json ä¸­çš„ MODEL_TYPE æ¨¡å¼")
                print(f"ğŸ¯ æ–°æ¨¡å¼: {pattern}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŒæ­¥å¤±æ•—: {e}")
            return False
    
    def validate_all(self):
        """é©—è­‰æ‰€æœ‰é…ç½®æª”æ¡ˆ"""
        print("ğŸ” é©—è­‰æ‰€æœ‰é…ç½®æª”æ¡ˆ...\n")
        
        all_valid = True
        
        # é©—è­‰entity_patterns
        print("1. é©—è­‰ entity_patterns.json:")
        result = subprocess.run([
            sys.executable, 
            str(project_root / "tools/entity_manager.py"), 
            "validate"
        ], capture_output=True, text=True, encoding='utf-8')
        
        if result.returncode == 0:
            print("âœ… entity_patterns.json é©—è­‰é€šé")
        else:
            print("âŒ entity_patterns.json é©—è­‰å¤±æ•—")
            print(result.stdout)
            all_valid = False
        
        print()
        
        # é©—è­‰query_keywords
        print("2. é©—è­‰ query_keywords.json:")
        result = subprocess.run([
            sys.executable, 
            str(project_root / "tools/keywords_manager.py"), 
            "validate"
        ], capture_output=True, text=True, encoding='utf-8')
        
        if result.returncode == 0:
            print("âœ… query_keywords.json é©—è­‰é€šé")
        else:
            print("âŒ query_keywords.json é©—è­‰å¤±æ•—")
            print(result.stdout)
            all_valid = False
        
        print()
        
        if all_valid:
            print("ğŸ‰ æ‰€æœ‰é…ç½®æª”æ¡ˆé©—è­‰é€šéï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†é…ç½®æª”æ¡ˆå­˜åœ¨å•é¡Œï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤è¨Šæ¯")
        
        return all_valid
    
    def backup_all(self):
        """å‚™ä»½æ‰€æœ‰é…ç½®æª”æ¡ˆ"""
        print("ğŸ“‹ å‚™ä»½æ‰€æœ‰é…ç½®æª”æ¡ˆ...")
        
        for config_name in self.config_files.keys():
            self._create_backup(config_name)
        
        print("âœ… å‚™ä»½å®Œæˆ")
    
    def _create_backup(self, config_type: str):
        """å»ºç«‹å‚™ä»½æª”æ¡ˆ"""
        if config_type not in self.config_files:
            print(f"âŒ æœªçŸ¥é…ç½®é¡å‹: {config_type}")
            return
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"{config_type}_{timestamp}.json"
        
        try:
            import shutil
            shutil.copy2(self.config_files[config_type], backup_file)
            print(f"ğŸ“‹ å·²å»ºç«‹å‚™ä»½: {backup_file}")
        except Exception as e:
            print(f"âš ï¸  å»ºç«‹ {config_type} å‚™ä»½å¤±æ•—: {e}")
    
    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å‚™ä»½æª”æ¡ˆ"""
        if not self.backup_dir.exists():
            print("âŒ å‚™ä»½ç›®éŒ„ä¸å­˜åœ¨")
            return
        
        backup_files = list(self.backup_dir.glob("*.json"))
        if not backup_files:
            print("ğŸ“‚ æ²’æœ‰æ‰¾åˆ°å‚™ä»½æª”æ¡ˆ")
            return
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
        backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        table_data = []
        for backup_file in backup_files:
            stat = backup_file.stat()
            from datetime import datetime
            mtime = datetime.fromtimestamp(stat.st_mtime)
            
            table_data.append([
                backup_file.name,
                f"{stat.st_size} bytes",
                mtime.strftime("%Y-%m-%d %H:%M:%S")
            ])
        
        headers = ['å‚™ä»½æª”æ¡ˆ', 'å¤§å°', 'å»ºç«‹æ™‚é–“']
        print("\nğŸ“‹ å‚™ä»½æª”æ¡ˆåˆ—è¡¨:")
        print(tabulate(table_data, headers=headers, tablefmt='grid'))
    
    def restore_backup(self, backup_file: str):
        """å¾å‚™ä»½æª”æ¡ˆé‚„åŸé…ç½®"""
        backup_path = self.backup_dir / backup_file
        if not backup_path.exists():
            print(f"âŒ å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: {backup_file}")
            return False
        
        # åˆ¤æ–·é…ç½®é¡å‹
        config_type = None
        for ct in self.config_files.keys():
            if backup_file.startswith(ct):
                config_type = ct
                break
        
        if not config_type:
            print(f"âŒ ç„¡æ³•è­˜åˆ¥å‚™ä»½æª”æ¡ˆé¡å‹: {backup_file}")
            return False
        
        try:
            # å»ºç«‹ç•¶å‰é…ç½®çš„å‚™ä»½
            self._create_backup(config_type)
            
            # é‚„åŸå‚™ä»½
            import shutil
            shutil.copy2(backup_path, self.config_files[config_type])
            print(f"âœ… å·²å¾ {backup_file} é‚„åŸ {config_type} é…ç½®")
            return True
            
        except Exception as e:
            print(f"âŒ é‚„åŸå¤±æ•—: {e}")
            return False
    
    def summary(self):
        """é¡¯ç¤ºé…ç½®æ‘˜è¦"""
        print("ğŸ“Š Sales Assistant é…ç½®æ‘˜è¦:\n")
        
        # Entity Patterns æ‘˜è¦
        entity_data = self._load_config('entity_patterns')
        entity_patterns = entity_data.get('entity_patterns', {})
        
        print("ğŸ¯ å¯¦é«”æ¨¡å¼ (Entity Patterns):")
        for entity_type, config in entity_patterns.items():
            pattern_count = len(config.get('patterns', []))
            example_count = len(config.get('examples', []))
            print(f"  â€¢ {entity_type}: {pattern_count} å€‹æ¨¡å¼, {example_count} å€‹ç¯„ä¾‹")
        
        print()
        
        # Query Keywords æ‘˜è¦
        keywords_data = self._load_config('query_keywords')
        intent_keywords = keywords_data.get('intent_keywords', {})
        
        print("ğŸ” æŸ¥è©¢é—œéµå­— (Query Keywords):")
        total_keywords = 0
        for intent_name, config in intent_keywords.items():
            keyword_count = len(config.get('keywords', []))
            total_keywords += keyword_count
            print(f"  â€¢ {intent_name}: {keyword_count} å€‹é—œéµå­—")
        
        print(f"\nğŸ“ˆ ç¸½è¨ˆ: {len(entity_patterns)} å€‹å¯¦é«”é¡å‹, {len(intent_keywords)} å€‹æ„åœ–, {total_keywords} å€‹é—œéµå­—")
    
    def export_config(self, format: str = 'json'):
        """åŒ¯å‡ºå®Œæ•´é…ç½®"""
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if format == 'json':
            export_data = {}
            for config_name in self.config_files.keys():
                export_data[config_name] = self._load_config(config_name)
            
            filename = f"sales_assistant_config_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å·²åŒ¯å‡ºå®Œæ•´é…ç½®åˆ° {filename}")
        
        elif format == 'summary':
            filename = f"config_summary_{timestamp}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                # é‡å®šå‘stdoutåˆ°æª”æ¡ˆ
                import io
                old_stdout = sys.stdout
                sys.stdout = buffer = io.StringIO()
                
                self.summary()
                
                sys.stdout = old_stdout
                f.write(buffer.getvalue())
            
            print(f"âœ… å·²åŒ¯å‡ºé…ç½®æ‘˜è¦åˆ° {filename}")

def main():
    parser = argparse.ArgumentParser(description='Sales Assistant é…ç½®ç®¡ç†å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # status å‘½ä»¤
    subparsers.add_parser('status', help='é¡¯ç¤ºé…ç½®æª”æ¡ˆç‹€æ…‹')
    
    # sync å‘½ä»¤
    subparsers.add_parser('sync', help='åŒæ­¥æ•¸æ“šåº«ä¸­çš„modeltypeåˆ°é…ç½®æª”æ¡ˆ')
    
    # validate å‘½ä»¤
    subparsers.add_parser('validate', help='é©—è­‰æ‰€æœ‰é…ç½®æª”æ¡ˆ')
    
    # backup å‘½ä»¤
    subparsers.add_parser('backup', help='å‚™ä»½æ‰€æœ‰é…ç½®æª”æ¡ˆ')
    
    # list-backups å‘½ä»¤
    subparsers.add_parser('list-backups', help='åˆ—å‡ºæ‰€æœ‰å‚™ä»½æª”æ¡ˆ')
    
    # restore å‘½ä»¤
    restore_parser = subparsers.add_parser('restore', help='å¾å‚™ä»½é‚„åŸé…ç½®')
    restore_parser.add_argument('backup_file', help='å‚™ä»½æª”æ¡ˆåç¨±')
    
    # summary å‘½ä»¤
    subparsers.add_parser('summary', help='é¡¯ç¤ºé…ç½®æ‘˜è¦')
    
    # export å‘½ä»¤
    export_parser = subparsers.add_parser('export', help='åŒ¯å‡ºé…ç½®')
    export_parser.add_argument('--format', choices=['json', 'summary'], default='json', help='åŒ¯å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    manager = ConfigManager()
    
    if args.command == 'status':
        manager.status()
    
    elif args.command == 'sync':
        manager.sync_modeltypes()
    
    elif args.command == 'validate':
        manager.validate_all()
    
    elif args.command == 'backup':
        manager.backup_all()
    
    elif args.command == 'list-backups':
        manager.list_backups()
    
    elif args.command == 'restore':
        manager.restore_backup(args.backup_file)
    
    elif args.command == 'summary':
        manager.summary()
    
    elif args.command == 'export':
        manager.export_config(args.format)

if __name__ == '__main__':
    main()