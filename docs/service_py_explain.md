# SalesAssistantService æ ¸å¿ƒå‡½æ•¸æ¥µè©³ç´°è§£é‡‹

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±åˆå§‹åŒ–èˆ‡é…ç½®ç®¡ç†é¡](#ç³»çµ±åˆå§‹åŒ–èˆ‡é…ç½®ç®¡ç†é¡)
2. [æ•¸æ“šæ¢ç´¢èˆ‡ç²å–é¡](#æ•¸æ“šæ¢ç´¢èˆ‡ç²å–é¡)
3. [æŸ¥è©¢åˆ†æèˆ‡æ„åœ–è­˜åˆ¥é¡](#æŸ¥è©¢åˆ†æèˆ‡æ„åœ–è­˜åˆ¥é¡)
4. [è¡¨æ ¼è—è¡“èˆ‡æ ¼å¼åŒ–é¡](#è¡¨æ ¼è—è¡“èˆ‡æ ¼å¼åŒ–é¡)
5. [æ•¸æ“šè™•ç†èˆ‡ä¿®å¾©é¡](#æ•¸æ“šè™•ç†èˆ‡ä¿®å¾©é¡)
6. [LLMäº¤äº’èˆ‡æ™ºèƒ½è™•ç†é¡](#llmäº¤äº’èˆ‡æ™ºèƒ½è™•ç†é¡)
7. [å¤šè¼ªå°è©±ç®¡ç†é¡](#å¤šè¼ªå°è©±ç®¡ç†é¡)
8. [é…ç½®æ–‡ä»¶é—œä¿‚åœ–è§£](#é…ç½®æ–‡ä»¶é—œä¿‚åœ–è§£)

---

## ğŸ—ï¸ ç³»çµ±åˆå§‹åŒ–èˆ‡é…ç½®ç®¡ç†é¡

### 1. `__init__()` - ç³»çµ±ç¸½æŒ‡æ®å®˜çš„å°±è·å…¸ç¦®

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½æ–°ä¸Šä»»çš„ CEOï¼Œéœ€è¦ç†Ÿæ‚‰å…¬å¸å„éƒ¨é–€ã€å»ºç«‹ç®¡ç†é«”ç³»ã€é…ç½®æ ¸å¿ƒè³‡æº
- **æ ¸å¿ƒä½¿å‘½**: åˆå§‹åŒ– SalesAssistantService çš„æ‰€æœ‰æ ¸å¿ƒçµ„ä»¶å’Œä¾è³´é …
- **é‡è¦ç­‰ç´š**: â­â­â­â­â­ (ç³»çµ±ç”Ÿå‘½é€±æœŸçš„èµ·é»)
- **èª¿ç”¨é »ç‡**: ä½ (é€šå¸¸åªåœ¨ç³»çµ±å•Ÿå‹•æ™‚èª¿ç”¨ä¸€æ¬¡)
- **è¤‡é›œåº¦**: ä¸­ç­‰ (éœ€è¦å”èª¿å¤šå€‹å­ç³»çµ±)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–
```python
def __init__(self):
    # è¼¸å…¥: ç„¡é¡¯å¼åƒæ•¸ï¼Œä½†ä¾è³´å…¨åŸŸé…ç½®
    # è¼¸å‡º: å®Œå…¨åˆå§‹åŒ–çš„ SalesAssistantService å¯¦ä¾‹
```

**è¼¸å…¥è©³è§£:**
- ç„¡ç›´æ¥åƒæ•¸ï¼Œä½†ä¾è³´æ–¼ï¼š
  - å…¨åŸŸè®Šæ•¸ `AVAILABLE_MODELNAMES` å’Œ `AVAILABLE_MODELTYPES`
  - ç’°å¢ƒè®Šæ•¸å’Œé…ç½®æ–‡ä»¶ (`config.py`)
  - å¤–éƒ¨æœå‹™ (DuckDB, Milvus, Ollama LLM)

**è¼¸å‡ºè©³è§£:**
- è¿”å›å®Œå…¨åˆå§‹åŒ–çš„æœå‹™å¯¦ä¾‹ï¼ŒåŒ…å«ï¼š
  - `self.llm`: LLM å¯¦ä¾‹ (DeepSeek-R1 æ¨¡å‹)
  - `self.milvus_query`: å‘é‡æ•¸æ“šåº«æŸ¥è©¢å™¨
  - `self.duckdb_query`: çµæ§‹åŒ–æ•¸æ“šåº«æŸ¥è©¢å™¨
  - `self.prompt_template`: é è¼‰çš„æç¤ºæ¨¡æ¿
  - `self.intent_keywords`: æ„åœ–é—œéµå­—é…ç½®
  - `self.multichat_manager`: å¤šè¼ªå°è©±ç®¡ç†å™¨
  - `self.spec_fields`: è¦æ ¼æ¬„ä½å®šç¾©åˆ—è¡¨

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: LLM åˆå§‹åŒ– (ç¬¬88-90è¡Œ)**
```python
self.llm_initializer = LLMInitializer()
self.llm = self.llm_initializer.get_llm()
```
**éš±å–»**: å°±åƒ CEO ç¬¬ä¸€å¤©ä¸Šç­ï¼Œå…ˆç¢ºä¿æœ‰ä¸€ä½å„ªç§€çš„é¡§å• (LLM) å¯ä»¥æä¾›æ™ºèƒ½å»ºè­°ã€‚

**è©³ç´°éç¨‹**:
1. å‰µå»º `LLMInitializer` å¯¦ä¾‹
2. èª¿ç”¨ `get_llm()` æ–¹æ³•é€£æ¥åˆ° Ollama æœå‹™
3. é è¨­ä½¿ç”¨ "deepseek-r1:7b" æ¨¡å‹ï¼Œæº«åº¦è¨­ç‚º 0.1 (ç›¸å°ä¿å®ˆçš„å›æ‡‰)

**ç¬¬äºŒéšæ®µ: æ•¸æ“šåº«é€£æ¥å»ºç«‹ (ç¬¬92-96è¡Œ)**
```python
self.milvus_query = MilvusQuery(collection_name="sales_notebook_specs")
from config import DB_PATH
self.duckdb_query = DuckDBQuery(db_file=str(DB_PATH))
```
**éš±å–»**: CEO å»ºç«‹èˆ‡å…©å€‹é‡è¦éƒ¨é–€çš„è¯ç¹« - æƒ…å ±éƒ¨é–€ (Milvuså‘é‡æœç´¢) å’Œæª”æ¡ˆéƒ¨é–€ (DuckDBçµæ§‹åŒ–æŸ¥è©¢)ã€‚

**ç¬¬ä¸‰éšæ®µ: æ¨¡æ¿å’Œé…ç½®è¼‰å…¥ (ç¬¬98-101è¡Œ)**
```python
self.prompt_template = self._load_prompt_template("sales_rag_app/libs/services/sales_assistant/prompts/sales_prompt.txt")
self.intent_keywords = self._load_intent_keywords("sales_rag_app/libs/services/sales_assistant/prompts/query_keywords.json")
```
**éš±å–»**: CEO é–±è®€å…¬å¸çš„æ¨™æº–ä½œæ¥­ç¨‹åº (SOP) å’Œå®¢æˆ¶æœå‹™æ‰‹å†Šã€‚

**ç¬¬å››éšæ®µ: å¤šè¼ªå°è©±ç³»çµ±åˆå§‹åŒ– (ç¬¬103-105è¡Œ)**
```python
self.multichat_manager = MultichatManager()
self.chat_template_manager = ChatTemplateManager()
```
**éš±å–»**: å»ºç«‹å®¢æˆ¶æœå‹™éƒ¨é–€ï¼Œé…å‚™å°ˆæ¥­çš„å°è©±æµç¨‹é¡§å•ã€‚

**ç¬¬äº”éšæ®µ: è¦æ ¼æ¬„ä½å®šç¾© (ç¬¬108-116è¡Œ)**
```python
self.spec_fields = [
    'modeltype', 'version', 'modelname', 'mainboard', 'devtime',
    'pm', 'structconfig', 'lcd', 'touchpanel', 'iointerface', 
    # ... æ›´å¤šæ¬„ä½
]
```
**éš±å–»**: åˆ¶å®šå…¬å¸çš„ç”¢å“åˆ†é¡æ¨™æº–ï¼Œç¢ºä¿æ‰€æœ‰å“¡å·¥ä½¿ç”¨çµ±ä¸€çš„è¡“èªã€‚

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æˆåŠŸåˆå§‹åŒ–**
```python
# èª¿ç”¨
service = SalesAssistantService()

# æœŸæœ›çµæœ
assert service.llm is not None  # LLM æˆåŠŸè¼‰å…¥
assert service.duckdb_query is not None  # æ•¸æ“šåº«é€£æ¥æ­£å¸¸
assert len(service.spec_fields) == 26  # æ‰€æœ‰è¦æ ¼æ¬„ä½å·²å®šç¾©
assert 'cpu' in service.intent_keywords  # æ„åœ–é—œéµå­—å·²è¼‰å…¥
```

**ç¯„ä¾‹ 2: é…ç½®æ–‡ä»¶ç¼ºå¤±çš„éŒ¯èª¤è™•ç†**
```python
# å¦‚æœ query_keywords.json ä¸å­˜åœ¨
# _load_intent_keywords() æœƒè¿”å›ç©ºå­—å…¸
# service.intent_keywords = {}  # ä¸æœƒä¸­æ–·åˆå§‹åŒ–ï¼Œä½†åŠŸèƒ½å—é™
```

**ç¯„ä¾‹ 3: æ•¸æ“šåº«é€£æ¥å¤±æ•—**
```python
# å¦‚æœ DuckDB æª”æ¡ˆä¸å­˜åœ¨æˆ–æå£
# DuckDBQuery æ§‹é€ å‡½æ•¸æœƒæ‹‹å‡ºç•°å¸¸
# é€™æœƒå°è‡´æ•´å€‹åˆå§‹åŒ–å¤±æ•—
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `query_keywords.json` çš„é—œä¿‚:**
- **è®€å–æ™‚æ©Ÿ**: åˆå§‹åŒ–æ™‚ç«‹å³è¼‰å…¥
- **ä½¿ç”¨æ–¹å¼**: é€šé `_load_intent_keywords()` è®€å–
- **æ•¸æ“šçµæ§‹**:
```json
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    }
  }
}
```
- **å½±éŸ¿ç¯„åœ**: å½±éŸ¿æ•´å€‹æœå‹™çš„æ„åœ–è­˜åˆ¥èƒ½åŠ›

**èˆ‡ `sales_prompt.txt` çš„é—œä¿‚:**
- **è®€å–æ™‚æ©Ÿ**: åˆå§‹åŒ–æ™‚è¼‰å…¥ç‚ºæ¨¡æ¿
- **ä½¿ç”¨æ–¹å¼**: ä½œç‚º LLM çš„æç¤ºè©åŸºç¤
- **é è™•ç†**: æ”¯æ´ `{context}` å’Œ `{query}` è®Šæ•¸æ›¿æ›

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ“´å±•åˆå§‹åŒ–éç¨‹:**
1. **æ·»åŠ æ–°çš„æ•¸æ“šæº**: åœ¨ç¬¬äºŒéšæ®µå¾Œæ·»åŠ æ–°çš„æŸ¥è©¢å™¨
2. **å¢åŠ é…ç½®æ–‡ä»¶**: åœ¨ç¬¬ä¸‰éšæ®µæ·»åŠ æ–°çš„è¼‰å…¥é‚è¼¯
3. **ä¿®æ”¹è¦æ ¼æ¬„ä½**: æ›´æ–° `spec_fields` åˆ—è¡¨ä»¥åŒ¹é…æ•¸æ“šåº«çµæ§‹

**å¸¸è¦‹é™·é˜±:**
- âŒ å¿˜è¨˜è™•ç†é…ç½®æ–‡ä»¶ç¼ºå¤±çš„æƒ…æ³
- âŒ å‡è¨­æ‰€æœ‰å¤–éƒ¨æœå‹™éƒ½èƒ½æ­£å¸¸é€£æ¥
- âŒ ç¡¬ç·¨ç¢¼æ–‡ä»¶è·¯å¾‘ï¼Œä¸è€ƒæ…®éƒ¨ç½²ç’°å¢ƒå·®ç•°

**èª¿è©¦æŠ€å·§:**
- ğŸ” æª¢æŸ¥æ—¥èªŒè¼¸å‡ºï¼Œç¢ºèªæ¯å€‹çµ„ä»¶çš„åˆå§‹åŒ–ç‹€æ…‹
- ğŸ” ä½¿ç”¨ `hasattr()` æª¢æŸ¥å±¬æ€§æ˜¯å¦æ­£ç¢ºè¨­ç½®
- ğŸ” åˆ†éšæ®µæ¸¬è©¦ï¼Œé€å€‹é©—è­‰æ¯å€‹çµ„ä»¶

---

### 2. `_load_prompt_template()` - åŠ‡æœ¬å°æ¼”çš„å°è©æœ¬è®€å–å™¨

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½åŠ‡å ´å°æ¼”çš„åŠ©æ‰‹ï¼Œè² è²¬å¾æª”æ¡ˆæ«ƒä¸­å–å‡ºæ¼”å“¡çš„å°è©æœ¬
- **æ ¸å¿ƒä½¿å‘½**: å¾æŒ‡å®šè·¯å¾‘è®€å– LLM æç¤ºè©æ¨¡æ¿æ–‡ä»¶
- **é‡è¦ç­‰ç´š**: â­â­â­ (å½±éŸ¿ LLM å›æ‡‰å“è³ª)
- **èª¿ç”¨é »ç‡**: ä½ (é€šå¸¸åªåœ¨åˆå§‹åŒ–æ™‚èª¿ç”¨)
- **è¤‡é›œåº¦**: ç°¡å–® (ç´”æ–‡ä»¶è®€å–æ“ä½œ)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def _load_prompt_template(self, path: str) -> str:
    # è¼¸å…¥: æ–‡ä»¶è·¯å¾‘å­—ä¸²
    # è¼¸å‡º: æç¤ºè©æ¨¡æ¿å…§å®¹ (å­—ä¸²)
```

**è¼¸å…¥åƒæ•¸è©³è§£:**
- `path: str`: æç¤ºè©æ¨¡æ¿æ–‡ä»¶çš„çµ•å°æˆ–ç›¸å°è·¯å¾‘
  - ç¯„ä¾‹: `"sales_rag_app/libs/services/sales_assistant/prompts/sales_prompt.txt"`
  - é æœŸæ–‡ä»¶æ ¼å¼: UTF-8 ç·¨ç¢¼çš„ç´”æ–‡å­—æª”
  - æ”¯æ´è®Šæ•¸: `{context}`, `{query}` ç­‰é ç•™ä½ç½®

**è¼¸å‡ºçµæœè©³è§£:**
- è¿”å›å®Œæ•´çš„æç¤ºè©æ¨¡æ¿å­—ä¸²
- åŒ…å«ç”¨æ–¼ LLM çš„æŒ‡ä»¤ã€æ ¼å¼è¦æ±‚ã€ç¯„ä¾‹ç­‰
- æ”¯æ´å¤šè¡Œæ–‡æœ¬ï¼Œä¿ç•™åŸå§‹æ ¼å¼

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

```python
def _load_prompt_template(self, path: str) -> str:
    with open(path, 'r', encoding='utf-8') as f:
        return f.read()
```

**è©³ç´°åŸ·è¡Œæ­¥é©Ÿ:**
1. **æ–‡ä»¶é–‹å•Ÿ**: ä½¿ç”¨ UTF-8 ç·¨ç¢¼é–‹å•ŸæŒ‡å®šè·¯å¾‘çš„æ–‡ä»¶
2. **å…§å®¹è®€å–**: ä¸€æ¬¡æ€§è®€å–æ•´å€‹æ–‡ä»¶å…§å®¹åˆ°è¨˜æ†¶é«”
3. **è‡ªå‹•é—œé–‰**: ä½¿ç”¨ `with` èªå¥ç¢ºä¿æ–‡ä»¶æ­£ç¢ºé—œé–‰

**éŒ¯èª¤è™•ç†åˆ†æ:**
- ç›®å‰å¯¦ä½œæ²’æœ‰é¡¯å¼éŒ¯èª¤è™•ç†
- å¯èƒ½æ‹‹å‡ºçš„ç•°å¸¸:
  - `FileNotFoundError`: æ–‡ä»¶ä¸å­˜åœ¨
  - `PermissionError`: æ²’æœ‰è®€å–æ¬Šé™
  - `UnicodeDecodeError`: æ–‡ä»¶ç·¨ç¢¼å•é¡Œ

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æˆåŠŸè¼‰å…¥æç¤ºè©**
```python
# å‡è¨­ sales_prompt.txt å…§å®¹å¦‚ä¸‹:
"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç­†é›»éŠ·å”®é¡§å•ã€‚
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šå›ç­”ç”¨æˆ¶å•é¡Œ:

è³‡æ–™: {context}
å•é¡Œ: {query}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«:
- answer_summary: è©³ç´°åˆ†æ
- comparison_table: æ¯”è¼ƒè¡¨æ ¼
"""

# å‡½æ•¸èª¿ç”¨
template = service._load_prompt_template("prompts/sales_prompt.txt")

# æœŸæœ›çµæœ
assert "{context}" in template
assert "{query}" in template
assert "JSON" in template
```

**ç¯„ä¾‹ 2: æ–‡ä»¶ä¸å­˜åœ¨çš„è™•ç†**
```python
try:
    template = service._load_prompt_template("nonexistent_file.txt")
except FileNotFoundError:
    print("æç¤ºè©æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨")
    # æ‡‰è©²ä½¿ç”¨é è¨­æ¨¡æ¿æˆ–æ‹‹å‡ºæ›´å‹å–„çš„éŒ¯èª¤
```

**ç¯„ä¾‹ 3: ç·¨ç¢¼å•é¡Œè™•ç†**
```python
# å¦‚æœæ–‡ä»¶åŒ…å«é UTF-8 å­—ç¬¦
try:
    template = service._load_prompt_template("bad_encoding.txt")
except UnicodeDecodeError:
    print("æ–‡ä»¶ç·¨ç¢¼ä¸æ­£ç¢ºï¼Œè«‹ç¢ºä¿ä½¿ç”¨ UTF-8")
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `sales_prompt.txt` çš„é—œä¿‚:**
- **æ–‡ä»¶çµæ§‹**: ç´”æ–‡å­—æª”ï¼ŒåŒ…å« LLM æŒ‡ä»¤
- **è®Šæ•¸ä½”ä½ç¬¦**: 
  - `{context}`: æœƒè¢«å¯¦éš›çš„ç­†é›»è¦æ ¼è³‡æ–™æ›¿æ›
  - `{query}`: æœƒè¢«ç”¨æˆ¶çš„æŸ¥è©¢å…§å®¹æ›¿æ›
- **æ ¼å¼è¦æ±‚**: æª”æ¡ˆä¸­å®šç¾©äº†æœŸæœ›çš„å›æ‡‰æ ¼å¼ (JSON)

**æ¨¡æ¿å…§å®¹ç¯„ä¾‹:**
```text
ä½ æ˜¯ç­†é›»éŠ·å”®å°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹è³‡æ–™ï¼š

ä¸Šä¸‹æ–‡è³‡è¨Š: {context}
ç”¨æˆ¶æŸ¥è©¢: {query}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{
  "answer_summary": "è©³ç´°çš„å›ç­”æ‘˜è¦",
  "comparison_table": [
    {"feature": "CPU", "model1": "spec1", "model2": "spec2"}
  ]
}
```

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ”¹é€²é€™å€‹å‡½æ•¸:**
```python
def _load_prompt_template(self, path: str) -> str:
    try:
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content.strip():
                raise ValueError("æç¤ºè©æ¨¡æ¿æ–‡ä»¶ç‚ºç©º")
            return content
    except FileNotFoundError:
        logging.error(f"æç¤ºè©æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return self._get_default_prompt_template()
    except UnicodeDecodeError:
        logging.error(f"æç¤ºè©æ¨¡æ¿ç·¨ç¢¼éŒ¯èª¤: {path}")
        raise ValueError("æ–‡ä»¶å¿…é ˆä½¿ç”¨ UTF-8 ç·¨ç¢¼")
```

**æ“´å±•åŠŸèƒ½å»ºè­°:**
1. **æ¨¡æ¿é©—è­‰**: æª¢æŸ¥å¿…è¦çš„ä½”ä½ç¬¦æ˜¯å¦å­˜åœ¨
2. **æ¨¡æ¿å¿«å–**: é¿å…é‡è¤‡è®€å–ç›¸åŒæ–‡ä»¶
3. **å‹•æ…‹è¼‰å…¥**: æ”¯æ´é‹è¡Œæ™‚é‡æ–°è¼‰å…¥æ¨¡æ¿
4. **å¤šèªè¨€æ”¯æ´**: æ ¹æ“šèªè¨€è¨­å®šè¼‰å…¥ä¸åŒæ¨¡æ¿

---

### 3. `_load_intent_keywords()` - æ™ºèƒ½è©å…¸ç®¡ç†å“¡

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½åœ–æ›¸é¤¨çš„åƒè€ƒè«®è©¢å°ˆå®¶ï¼Œç¶­è­·è‘—ä¸€æœ¬è©³ç´°çš„ã€Œç”¨æˆ¶æ„åœ–è­˜åˆ¥è©å…¸ã€
- **æ ¸å¿ƒä½¿å‘½**: è¼‰å…¥å’Œè§£ææŸ¥è©¢æ„åœ–é—œéµå­—é…ç½®æ–‡ä»¶ï¼Œç‚ºæ„åœ–è­˜åˆ¥æä¾›åŸºç¤
- **é‡è¦ç­‰ç´š**: â­â­â­â­ (ç›´æ¥å½±éŸ¿æŸ¥è©¢ç†è§£èƒ½åŠ›)
- **èª¿ç”¨é »ç‡**: ä½ (åˆå§‹åŒ–å’Œé‡æ–°è¼‰å…¥æ™‚)
- **è¤‡é›œåº¦**: ä¸­ç­‰ (åŒ…å« JSON è§£æå’ŒéŒ¯èª¤è™•ç†)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def _load_intent_keywords(self, path: str) -> dict:
    # è¼¸å…¥: JSON é…ç½®æ–‡ä»¶è·¯å¾‘
    # è¼¸å‡º: æ„åœ–é—œéµå­—å­—å…¸
```

**è¼¸å…¥åƒæ•¸è©³è§£:**
- `path: str`: æŒ‡å‘ `query_keywords.json` çš„æ–‡ä»¶è·¯å¾‘
- æª”æ¡ˆæ ¼å¼è¦æ±‚:
  ```json
  {
    "intent_keywords": {
      "cpu": {
        "keywords": ["cpu", "è™•ç†å™¨", "processor"],
        "description": "CPUç›¸é—œæŸ¥è©¢"
      }
    }
  }
  ```

**è¼¸å‡ºçµæœè©³è§£:**
- æˆåŠŸæ™‚: è¿”å›åµŒå¥—å­—å…¸çµæ§‹
  ```python
  {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    },
    "gpu": {
      "keywords": ["gpu", "é¡¯å¡", "graphics"],
      "description": "GPUç›¸é—œæŸ¥è©¢"
    }
  }
  ```
- å¤±æ•—æ™‚: è¿”å›ç©ºå­—å…¸ `{}`

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: å®‰å…¨è¼‰å…¥èˆ‡è§£æ (ç¬¬126-130è¡Œ)**
```python
try:
    with open(path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        logging.info(f"æˆåŠŸè¼‰å…¥é—œéµå­—é…ç½®: {list(config.get('intent_keywords', {}).keys())}")
        return config.get('intent_keywords', {})
```

**éš±å–»**: åœ–æ›¸é¤¨å“¡å°å¿ƒç¿¼ç¿¼åœ°æ‰“é–‹çè²´çš„åƒè€ƒæ›¸ï¼Œç¢ºèªå…§å®¹å®Œæ•´å¾Œå°‡å…¶ä¸­çš„ã€Œæ„åœ–ç´¢å¼•ã€æå–å‡ºä¾†ã€‚

**è©³ç´°åŸ·è¡Œæ­¥é©Ÿ:**
1. ä½¿ç”¨ UTF-8 ç·¨ç¢¼é–‹å•Ÿ JSON æ–‡ä»¶
2. èª¿ç”¨ `json.load()` è§£æ JSON å…§å®¹
3. æå– `intent_keywords` éƒ¨åˆ†ï¼Œå¿½ç•¥å…¶ä»–å¯èƒ½çš„é…ç½®
4. è¨˜éŒ„æˆåŠŸè¼‰å…¥çš„æ„åœ–é¡å‹åˆ—è¡¨

**ç¬¬äºŒéšæ®µ: å¤šå±¤éŒ¯èª¤è™•ç† (ç¬¬131-139è¡Œ)**
```python
except FileNotFoundError:
    logging.error(f"é—œéµå­—é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    return {}
except json.JSONDecodeError as e:
    logging.error(f"é—œéµå­—é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
    return {}
except Exception as e:
    logging.error(f"è¼‰å…¥é—œéµå­—é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    return {}
```

**éŒ¯èª¤è™•ç†ç­–ç•¥åˆ†æ:**
- **FileNotFoundError**: æª”æ¡ˆä¸å­˜åœ¨ï¼Œè¨˜éŒ„éŒ¯èª¤ä½†ä¸ä¸­æ–·ç³»çµ±
- **JSONDecodeError**: JSON æ ¼å¼éŒ¯èª¤ï¼Œæä¾›å…·é«”éŒ¯èª¤ä¿¡æ¯
- **é€šç”¨ç•°å¸¸**: æ•ç²æ‰€æœ‰å…¶ä»–å¯èƒ½çš„éŒ¯èª¤

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æˆåŠŸè¼‰å…¥å®Œæ•´é…ç½®**
```python
# query_keywords.json å…§å®¹:
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor", "ryzen"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    },
    "gpu": {
      "keywords": ["gpu", "é¡¯å¡", "graphics", "radeon"],
      "description": "GPUç›¸é—œæŸ¥è©¢"
    },
    "memory": {
      "keywords": ["è¨˜æ†¶é«”", "å…§å­˜", "memory", "ram", "ddr"],
      "description": "è¨˜æ†¶é«”ç›¸é—œæŸ¥è©¢"
    }
  }
}

# å‡½æ•¸èª¿ç”¨
keywords = service._load_intent_keywords("prompts/query_keywords.json")

# é©—è­‰çµæœ
assert "cpu" in keywords
assert "gpu" in keywords
assert "memory" in keywords
assert len(keywords["cpu"]["keywords"]) == 4
assert keywords["cpu"]["description"] == "CPUç›¸é—œæŸ¥è©¢"
```

**ç¯„ä¾‹ 2: è™•ç†æ ¼å¼éŒ¯èª¤çš„ JSON**
```python
# æå£çš„ query_keywords.json:
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨",  // ç¼ºå°‘çµå°¾å¼•è™Ÿ
      "description": "CPUç›¸é—œæŸ¥è©¢"
    }
  }
}

# å‡½æ•¸èª¿ç”¨
keywords = service._load_intent_keywords("broken_keywords.json")

# æœŸæœ›çµæœ
assert keywords == {}  # è¿”å›ç©ºå­—å…¸
# æ—¥èªŒæœƒè¨˜éŒ„: "é—œéµå­—é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: Expecting ',' delimiter..."
```

**ç¯„ä¾‹ 3: è™•ç†ç©ºé…ç½®æ–‡ä»¶**
```python
# ç©ºçš„ query_keywords.json:
{}

# å‡½æ•¸èª¿ç”¨
keywords = service._load_intent_keywords("empty_keywords.json")

# çµæœåˆ†æ
assert keywords == {}  # å› ç‚ºæ²’æœ‰ 'intent_keywords' éµ
# ä½†ä¸æœƒå ±éŒ¯ï¼Œç³»çµ±æœƒæ­£å¸¸é‹è¡Œï¼Œåªæ˜¯æ„åœ–è­˜åˆ¥åŠŸèƒ½å—é™
```

**ç¯„ä¾‹ 4: è™•ç†ä¸å®Œæ•´çš„é…ç½®çµæ§‹**
```python
# ä¸å®Œæ•´çš„ query_keywords.json:
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨"]
      // ç¼ºå°‘ "description" æ¬„ä½
    }
  }
}

# å‡½æ•¸èª¿ç”¨æœƒæˆåŠŸï¼Œä½†å¾ŒçºŒä½¿ç”¨æ™‚éœ€è¦æª¢æŸ¥æ¬„ä½å­˜åœ¨æ€§
keywords = service._load_intent_keywords("incomplete_keywords.json")
description = keywords.get("cpu", {}).get("description", "ç„¡æè¿°")
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `query_keywords.json` çš„æ·±åº¦æ•´åˆ:**

**æ–‡ä»¶çµæ§‹è©³è§£:**
```json
{
  "intent_keywords": {
    "display": {
      "keywords": ["è¢å¹•", "é¡¯ç¤º", "screen", "lcd", "é¢æ¿"],
      "description": "è¢å¹•ç›¸é—œæŸ¥è©¢"
    },
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor", "ryzen"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    },
    "comparison": {
      "keywords": ["æ¯”è¼ƒ", "compare", "å·®ç•°", "difference", "ä¸åŒ"],
      "description": "æ¯”è¼ƒç›¸é—œæŸ¥è©¢"
    }
  }
}
```

**æ•¸æ“šæµå‘åˆ†æ:**
1. **è¼‰å…¥éšæ®µ**: `_load_intent_keywords()` â†’ `self.intent_keywords`
2. **ä½¿ç”¨éšæ®µ**: `_parse_query_intent()` ä½¿ç”¨é€™äº›é—œéµå­—é€²è¡Œæ„åœ–åŒ¹é…
3. **æ›´æ–°éšæ®µ**: `add_intent_keyword()`, `remove_intent_keyword()` ä¿®æ”¹å…§å®¹
4. **ä¿å­˜éšæ®µ**: `save_intent_keywords()` å°‡ä¿®æ”¹å¯«å›æ–‡ä»¶

**é—œéµå­—åŒ¹é…é‚è¼¯:**
```python
# åœ¨ _parse_query_intent() ä¸­çš„ä½¿ç”¨ç¯„ä¾‹
query_lower = query.lower()
for intent_name, intent_config in self.intent_keywords.items():
    keywords = intent_config.get("keywords", [])
    if any(keyword.lower() in query_lower for keyword in keywords):
        result["intent"] = intent_name
        break
```

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ“´å±•é—œéµå­—é…ç½®:**

1. **æ·»åŠ æ–°æ„åœ–é¡å‹:**
```json
{
  "intent_keywords": {
    "gaming": {
      "keywords": ["éŠæˆ²", "é›»ç«¶", "gaming", "fps", "é«˜ç•«è³ª"],
      "description": "éŠæˆ²æ•ˆèƒ½ç›¸é—œæŸ¥è©¢"
    }
  }
}
```

2. **å¤šèªè¨€æ”¯æ´:**
```json
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor", "ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼", "processeur"],
      "description": "CPUç›¸é—œæŸ¥è©¢ï¼ˆå¤šèªè¨€ï¼‰"
    }
  }
}
```

**æ€§èƒ½å„ªåŒ–å»ºè­°:**
- ğŸ“Š **å¿«å–æ©Ÿåˆ¶**: è¼‰å…¥å¾Œå¿«å–çµæœï¼Œé¿å…é‡è¤‡æ–‡ä»¶è®€å–
- ğŸ“Š **é—œéµå­—ç´¢å¼•**: å»ºç«‹åå‘ç´¢å¼•ï¼ŒåŠ é€Ÿé—œéµå­—æŸ¥æ‰¾
- ğŸ“Š **æ‡¶åŠ è¼‰**: åªåœ¨éœ€è¦æ™‚è¼‰å…¥ç‰¹å®šæ„åœ–çš„é—œéµå­—

**å¸¸è¦‹é™·é˜±å’Œè§£æ±ºæ–¹æ¡ˆ:**
- âŒ **é—œéµå­—é‡è¤‡**: ä¸åŒæ„åœ–åŒ…å«ç›¸åŒé—œéµå­—æœƒå°è‡´è¡çª
  - âœ… è§£æ±º: æŒ‰å„ªå…ˆç´šæ’åºï¼Œæˆ–ä½¿ç”¨æ¬Šé‡æ©Ÿåˆ¶
- âŒ **å¤§å°å¯«ä¸ä¸€è‡´**: å¿˜è¨˜çµ±ä¸€é—œéµå­—å¤§å°å¯«
  - âœ… è§£æ±º: åœ¨è¼‰å…¥æ™‚çµ±ä¸€è½‰æ›ç‚ºå°å¯«
- âŒ **ç‰¹æ®Šå­—ç¬¦è™•ç†**: é—œéµå­—åŒ…å«æ­£å‰‡è¡¨é”å¼ç‰¹æ®Šå­—ç¬¦
  - âœ… è§£æ±º: ä½¿ç”¨ `re.escape()` é€²è¡Œè½‰ç¾©

---

## ğŸ” æ•¸æ“šæ¢ç´¢èˆ‡ç²å–é¡

### 4. `_get_available_modelnames_from_db()` - ç”¢å“ç›®éŒ„å®ˆè­·è€…

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½ç”¢å“ç›®éŒ„çš„åœ–æ›¸ç®¡ç†å“¡ï¼Œè² è²¬ç¶­è­·æœ€æ–°çš„ç­†é›»å‹è™Ÿæ¸…å–®
- **æ ¸å¿ƒä½¿å‘½**: å¾ DuckDB æ•¸æ“šåº«å‹•æ…‹ç²å–æ‰€æœ‰å¯ç”¨çš„ç­†é›»å‹è™Ÿåç¨±
- **é‡è¦ç­‰ç´š**: â­â­â­â­ (å½±éŸ¿æ•´å€‹ç³»çµ±çš„ç”¢å“è­˜åˆ¥èƒ½åŠ›)
- **èª¿ç”¨é »ç‡**: ä½ (åƒ…åœ¨ç³»çµ±å•Ÿå‹•æ™‚èª¿ç”¨)
- **è¤‡é›œåº¦**: ä¸­ç­‰ (åŒ…å«æ•¸æ“šåº«æŸ¥è©¢å’ŒéŒ¯èª¤è™•ç†)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def _get_available_modelnames_from_db():
    # è¼¸å…¥: ç„¡ (ä½†ä¾è³´ config.DB_PATH å’Œæ•¸æ“šåº«é€£æ¥)
    # è¼¸å‡º: List[str] - ç­†é›»å‹è™Ÿåç¨±åˆ—è¡¨
```

**éš±å¼è¼¸å…¥ä¾è³´:**
- `config.DB_PATH`: æ•¸æ“šåº«æª”æ¡ˆè·¯å¾‘
- DuckDB æ•¸æ“šåº«çš„ `specs` è¡¨
- è¡¨çµæ§‹è¦æ±‚: å¿…é ˆåŒ…å« `modelname` æ¬„ä½

**è¼¸å‡ºçµæœè©³è§£:**
- **æˆåŠŸæƒ…æ³**: è¿”å›æ’åºçš„å‹è™Ÿåç¨±åˆ—è¡¨
  ```python
  ['AB819-S: FP6', 'AG958', 'AG958P', 'APX958', 'AHP819: FP7R2', ...]
  ```
- **å¤±æ•—æƒ…æ³**: è¿”å›é è¨­çš„ç¡¬ç·¨ç¢¼å‹è™Ÿåˆ—è¡¨ (ç¬¬42-46è¡Œ)

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: æ•¸æ“šåº«é€£æ¥èˆ‡æŸ¥è©¢ (ç¬¬21-34è¡Œ)**
```python
from config import DB_PATH
import duckdb

conn = duckdb.connect(str(DB_PATH))
result = conn.execute("""
    SELECT DISTINCT modelname 
    FROM specs 
    WHERE modelname IS NOT NULL 
      AND modelname != '' 
      AND modelname != 'Test Model'
    ORDER BY modelname
""").fetchall()
conn.close()
```

**éš±å–»**: åœ–æ›¸ç®¡ç†å“¡æ‰“é–‹ç”¢å“ç›®éŒ„æª”æ¡ˆæ«ƒï¼Œé€ä¸€æª¢æŸ¥æ¯å€‹æŠ½å±œï¼Œæ’é™¤ç©ºç™½å’Œæ¸¬è©¦è³‡æ–™ï¼Œå»ºç«‹å®Œæ•´çš„ç”¢å“æ¸…å–®ã€‚

**SQL æŸ¥è©¢åˆ†æ:**
- `SELECT DISTINCT modelname`: ç²å–ä¸é‡è¤‡çš„å‹è™Ÿåç¨±
- `WHERE modelname IS NOT NULL`: æ’é™¤ç©ºå€¼
- `AND modelname != ''`: æ’é™¤ç©ºå­—ç¬¦ä¸²
- `AND modelname != 'Test Model'`: æ’é™¤æ¸¬è©¦è³‡æ–™
- `ORDER BY modelname`: æŒ‰å­—æ¯é †åºæ’åº

**ç¬¬äºŒéšæ®µ: æ•¸æ“šè™•ç†èˆ‡æ—¥èªŒè¨˜éŒ„ (ç¬¬35-38è¡Œ)**
```python
modelnames = [row[0] for row in result]
logging.info(f"å¾æ•¸æ“šåº«ç²å–åˆ°çš„modelname: {len(modelnames)} å€‹")
return modelnames
```

**æ•¸æ“šè½‰æ›éç¨‹:**
1. `result` æ˜¯ tuple åˆ—è¡¨: `[('AG958',), ('APX958',), ...]`
2. ä½¿ç”¨åˆ—è¡¨æ¨å°å¼æå–ç¬¬ä¸€å€‹å…ƒç´ : `['AG958', 'APX958', ...]`
3. è¨˜éŒ„æˆåŠŸç²å–çš„å‹è™Ÿæ•¸é‡

**ç¬¬ä¸‰éšæ®µ: éŒ¯èª¤è™•ç†èˆ‡å‚™æ´æ©Ÿåˆ¶ (ç¬¬39-46è¡Œ)**
```python
except Exception as e:
    logging.error(f"ç²å–æ•¸æ“šåº«modelnameå¤±æ•—: {e}")
    return [
        'AB819-S: FP6', 'AG958', 'AG958P', 'AG958V', 'AHP819: FP7R2',
        'AHP839', 'AHP958', 'AKK839', 'AMD819-S: FT6', 'AMD819: FT6',
        'APX819: FP7R2', 'APX839', 'APX958', 'ARB819-S: FP7R2', 'ARB839'
    ]
```

**éš±å–»**: å¦‚æœæª”æ¡ˆæ«ƒé–ä½æˆ–æå£ï¼Œç®¡ç†å“¡æœƒæ‹¿å‡ºå‚™ç”¨çš„æ‰‹å¯«æ¸…å–®ï¼Œç¢ºä¿æ¥­å‹™ä¸ä¸­æ–·ã€‚

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æ­£å¸¸æ•¸æ“šåº«æŸ¥è©¢**
```python
# å‡è¨­æ•¸æ“šåº«åŒ…å«ä»¥ä¸‹æ•¸æ“š:
# specs è¡¨:
# | modelname    | cpu      | gpu      |
# |-------------|----------|----------|
# | AG958       | Ryzen 7  | Radeon   |
# | APX958      | Ryzen 9  | RTX      |
# | Test Model  | Test CPU | Test GPU |
# | NULL        | Intel i7 | Intel    |
# | ''          | AMD      | AMD      |

# å‡½æ•¸èª¿ç”¨
modelnames = _get_available_modelnames_from_db()

# æœŸæœ›çµæœ
expected = ['AG958', 'APX958']  # åªåŒ…å«æœ‰æ•ˆçš„å‹è™Ÿåç¨±
assert modelnames == expected
assert 'Test Model' not in modelnames  # æ¸¬è©¦è³‡æ–™è¢«æ’é™¤
assert '' not in modelnames  # ç©ºå­—ç¬¦ä¸²è¢«æ’é™¤
assert None not in modelnames  # NULL å€¼è¢«æ’é™¤
```

**ç¯„ä¾‹ 2: æ•¸æ“šåº«é€£æ¥å¤±æ•—**
```python
# æ¨¡æ“¬æ•¸æ“šåº«æª”æ¡ˆä¸å­˜åœ¨æˆ–æå£
# æ­¤æ™‚æœƒè§¸ç™¼ç•°å¸¸è™•ç†æ©Ÿåˆ¶

modelnames = _get_available_modelnames_from_db()

# æœŸæœ›çµæœ: ä½¿ç”¨å‚™ç”¨æ¸…å–®
expected_fallback = [
    'AB819-S: FP6', 'AG958', 'AG958P', 'AG958V', 'AHP819: FP7R2',
    'AHP839', 'AHP958', 'AKK839', 'AMD819-S: FT6', 'AMD819: FT6',
    'APX819: FP7R2', 'APX839', 'APX958', 'ARB819-S: FP7R2', 'ARB839'
]
assert modelnames == expected_fallback
assert len(modelnames) == 15  # å‚™ç”¨æ¸…å–®æœ‰ 15 å€‹å‹è™Ÿ
```

**ç¯„ä¾‹ 3: ç©ºæ•¸æ“šåº«è™•ç†**
```python
# å¦‚æœæ•¸æ“šåº«å­˜åœ¨ä½† specs è¡¨ç‚ºç©º
# æŸ¥è©¢æœƒè¿”å›ç©ºçµæœé›†

modelnames = _get_available_modelnames_from_db()

# æœŸæœ›çµæœ
assert modelnames == []  # ç©ºåˆ—è¡¨
# æ—¥èªŒæœƒé¡¯ç¤º: "å¾æ•¸æ“šåº«ç²å–åˆ°çš„modelname: 0 å€‹"
```

**ç¯„ä¾‹ 4: æ•¸æ“šæ¸…ç†æ•ˆæœé©—è­‰**
```python
# å‡è¨­æ•¸æ“šåº«åŒ…å«æ··äº‚çš„æ•¸æ“š:
# | modelname     |
# |---------------|
# | AG958         |  â† æœ‰æ•ˆ
# | Test Model    |  â† è¢«éæ¿¾
# | ''            |  â† è¢«éæ¿¾
# | NULL          |  â† è¢«éæ¿¾
# | APX958        |  â† æœ‰æ•ˆ
# | AG958         |  â† é‡è¤‡ï¼Œè¢« DISTINCT å»é™¤

modelnames = _get_available_modelnames_from_db()

# é©—è­‰æ¸…ç†æ•ˆæœ
assert 'AG958' in modelnames
assert 'APX958' in modelnames
assert 'Test Model' not in modelnames
assert '' not in modelnames
assert None not in modelnames
assert modelnames.count('AG958') == 1  # é‡è¤‡é …è¢«å»é™¤
assert modelnames == sorted(modelnames)  # å·²æ’åº
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `config.py` çš„é—œä¿‚:**
```python
# config.py ä¸­çš„è¨­å®š
DB_PATH = BASE_DIR / "db" / "sales_specs.db"

# å‡½æ•¸ä¸­çš„ä½¿ç”¨
from config import DB_PATH
conn = duckdb.connect(str(DB_PATH))
```

**èˆ‡æ•¸æ“šåº«çµæ§‹çš„é—œä¿‚:**
- **ä¾è³´è¡¨**: `specs` è¡¨
- **å¿…è¦æ¬„ä½**: `modelname` (å­—ä¸²é¡å‹)
- **è³‡æ–™å“è³ªè¦æ±‚**: 
  - ä¸èƒ½ç‚º NULL
  - ä¸èƒ½ç‚ºç©ºå­—ç¬¦ä¸²
  - ä¸èƒ½æ˜¯æ¸¬è©¦è³‡æ–™

**å…¨åŸŸè®Šæ•¸çš„è¨­å®š:**
```python
# åœ¨æ¨¡çµ„å±¤ç´šä½¿ç”¨
AVAILABLE_MODELNAMES = _get_available_modelnames_from_db()

# å¾ŒçºŒåœ¨å…¶ä»–å‡½æ•¸ä¸­ä½¿ç”¨
def _check_query_contains_modelname(self, query: str):
    for modelname in AVAILABLE_MODELNAMES:
        # æª¢æŸ¥é‚è¼¯...
```

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ”¹é€²é€™å€‹å‡½æ•¸:**

1. **å¢åŠ æ•¸æ“šé©—è­‰:**
```python
def _get_available_modelnames_from_db():
    try:
        # ... ç¾æœ‰é‚è¼¯ ...
        
        # æ·»åŠ æ•¸æ“šé©—è­‰
        if not modelnames:
            logging.warning("æ•¸æ“šåº«ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å‹è™Ÿåç¨±")
        
        # é©—è­‰å‹è™Ÿåç¨±æ ¼å¼
        valid_pattern = re.compile(r'[A-Z]{2,3}\d{3}')
        invalid_models = [m for m in modelnames if not valid_pattern.search(m)]
        if invalid_models:
            logging.warning(f"ç™¼ç¾æ ¼å¼ç•°å¸¸çš„å‹è™Ÿ: {invalid_models}")
        
        return modelnames
```

2. **æ·»åŠ ç·©å­˜æ©Ÿåˆ¶:**
```python
_MODEL_CACHE = None
_CACHE_TIMESTAMP = None

def _get_available_modelnames_from_db():
    global _MODEL_CACHE, _CACHE_TIMESTAMP
    
    # æª¢æŸ¥ç·©å­˜æ˜¯å¦æœ‰æ•ˆ (ä¾‹å¦‚ 1 å°æ™‚)
    if (_MODEL_CACHE is not None and 
        _CACHE_TIMESTAMP and 
        time.time() - _CACHE_TIMESTAMP < 3600):
        return _MODEL_CACHE
    
    # é‡æ–°æŸ¥è©¢æ•¸æ“šåº«
    modelnames = _query_database()
    _MODEL_CACHE = modelnames
    _CACHE_TIMESTAMP = time.time()
    
    return modelnames
```

3. **æ›´æ™ºèƒ½çš„å‚™æ´ç­–ç•¥:**
```python
def _get_available_modelnames_from_db():
    try:
        # å˜—è©¦å¾ä¸»æ•¸æ“šåº«ç²å–
        return _query_main_database()
    except Exception as e:
        logging.error(f"ä¸»æ•¸æ“šåº«æŸ¥è©¢å¤±æ•—: {e}")
        try:
            # å˜—è©¦å¾å‚™ä»½æ•¸æ“šåº«ç²å–
            return _query_backup_database()
        except Exception as e2:
            logging.error(f"å‚™ä»½æ•¸æ“šåº«ä¹Ÿå¤±æ•—: {e2}")
            # æœ€å¾Œä½¿ç”¨ç¡¬ç·¨ç¢¼åˆ—è¡¨
            return _get_hardcoded_models()
```

**æ€§èƒ½å„ªåŒ–å»ºè­°:**
- ğŸ“Š **é€£æ¥æ± **: ä½¿ç”¨æ•¸æ“šåº«é€£æ¥æ± é¿å…é »ç¹å»ºç«‹é€£æ¥
- ğŸ“Š **ç´¢å¼•å„ªåŒ–**: åœ¨ `modelname` æ¬„ä½ä¸Šå»ºç«‹ç´¢å¼•
- ğŸ“Š **åˆ†é æŸ¥è©¢**: å¦‚æœå‹è™Ÿæ•¸é‡å¾ˆå¤§ï¼Œè€ƒæ…®åˆ†é è¼‰å…¥

**ç›£æ§å’Œè­¦å‘Šæ©Ÿåˆ¶:**
- ğŸ”” **å‹è™Ÿæ•¸é‡ç›£æ§**: å¦‚æœå‹è™Ÿæ•¸é‡çªç„¶è®Šå°‘ï¼Œç™¼å‡ºè­¦å‘Š
- ğŸ”” **æ ¼å¼é©—è­‰**: æª¢æŸ¥æ–°å‹è™Ÿæ˜¯å¦ç¬¦åˆå‘½åè¦ç¯„
- ğŸ”” **é‡è¤‡æª¢æ¸¬**: ç™¼ç¾æ•¸æ“šåº«ä¸­æœ‰é‡è¤‡å‹è™Ÿæ™‚è­¦å‘Š

---

### 5. `_parse_query_intent()` - å®¢æˆ¶å¿ƒç†åˆ†æå¤§å¸«

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½ç¶“é©—è±å¯Œçš„å¿ƒç†å­¸å®¶å…¼åµæ¢ï¼Œèƒ½å¾å®¢æˆ¶çš„éš»è¨€ç‰‡èªä¸­æ´å¯ŸçœŸæ­£çš„éœ€æ±‚å’Œæ„åœ–
- **æ ¸å¿ƒä½¿å‘½**: åˆ†æç”¨æˆ¶æŸ¥è©¢ï¼Œè­˜åˆ¥å…¶ä¸­åŒ…å«çš„å‹è™Ÿåç¨±ã€ç³»åˆ—é¡å‹å’ŒæŸ¥è©¢æ„åœ–
- **é‡è¦ç­‰ç´š**: â­â­â­â­â­ (æ•´å€‹ RAG ç³»çµ±çš„æ ¸å¿ƒå…¥å£)
- **èª¿ç”¨é »ç‡**: é«˜ (æ¯æ¬¡ç”¨æˆ¶æŸ¥è©¢éƒ½æœƒèª¿ç”¨)
- **è¤‡é›œåº¦**: è¤‡é›œ (å¤šé‡è§£æé‚è¼¯å’Œæ„åœ–è­˜åˆ¥)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def _parse_query_intent(self, query: str) -> dict:
    # è¼¸å…¥: ç”¨æˆ¶åŸå§‹æŸ¥è©¢å­—ä¸²
    # è¼¸å‡º: çµæ§‹åŒ–çš„æŸ¥è©¢æ„åœ–å­—å…¸
```

**è¼¸å…¥åƒæ•¸è©³è§£:**
- `query: str`: ç”¨æˆ¶çš„è‡ªç„¶èªè¨€æŸ¥è©¢
  - ç¯„ä¾‹: `"æ¯”è¼ƒ AG958 å’Œ APX958 çš„ CPU æ€§èƒ½"`
  - ç¯„ä¾‹: `"958 ç³»åˆ—æœ‰å“ªäº›ç­†é›»ï¼Ÿ"`
  - ç¯„ä¾‹: `"æˆ‘æƒ³è¦ä¸€å°é©åˆéŠæˆ²çš„ç­†é›»"`

**è¼¸å‡ºçµæœè©³è§£:**
```python
{
    "modelnames": ["AG958", "APX958"],        # è­˜åˆ¥å‡ºçš„å…·é«”å‹è™Ÿ
    "modeltypes": ["958"],                    # è­˜åˆ¥å‡ºçš„ç³»åˆ—é¡å‹
    "intent": "comparison",                   # æŸ¥è©¢æ„åœ–
    "query_type": "specific_model"           # æŸ¥è©¢é¡å‹åˆ†é¡
}
```

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: åˆå§‹åŒ–çµæœçµæ§‹ (ç¬¬924-931è¡Œ)**
```python
result = {
    "modelnames": [],
    "modeltypes": [],
    "intent": "general",  # é»˜è®¤æ„å›¾
    "query_type": "unknown"  # æŸ¥è¯¢ç±»å‹
}
```

**éš±å–»**: å¿ƒç†å­¸å®¶æº–å‚™ä¸€å¼µç©ºç™½çš„åˆ†æè¡¨æ ¼ï¼Œæº–å‚™è¨˜éŒ„å¾æ‚£è€…è©±èªä¸­ç™¼ç¾çš„ç·šç´¢ã€‚

**ç¬¬äºŒéšæ®µ: å‹è™Ÿåç¨±è­˜åˆ¥ (ç¬¬933-937è¡Œ)**
```python
contains_modelname, found_modelnames = self._check_query_contains_modelname(query)
if contains_modelname:
    result["modelnames"] = found_modelnames
    result["query_type"] = "specific_model"
```

**è©³ç´°åˆ†æéç¨‹:**
1. èª¿ç”¨å°ˆé–€çš„å‹è™Ÿæª¢æ¸¬å‡½æ•¸
2. å¦‚æœç™¼ç¾å…·é«”å‹è™Ÿï¼Œæ¨™è¨˜æŸ¥è©¢é¡å‹ç‚º "specific_model"
3. é€™ç¨®æŸ¥è©¢é€šå¸¸å„ªå…ˆç´šæœ€é«˜ï¼Œå› ç‚ºç”¨æˆ¶å·²ç¶“æ˜ç¢ºæŒ‡å®šç”¢å“

**ç¬¬ä¸‰éšæ®µ: ç³»åˆ—é¡å‹è­˜åˆ¥ (ç¬¬939-944è¡Œ)**
```python
contains_modeltype, found_modeltypes = self._check_query_contains_modeltype(query)
if contains_modeltype:
    result["modeltypes"] = found_modeltypes
    if result["query_type"] == "unknown":
        result["query_type"] = "model_type"
```

**é‚è¼¯æ±ºç­–æ¨¹:**
- å¦‚æœå·²ç¶“è­˜åˆ¥å‡ºå…·é«”å‹è™Ÿï¼Œä¿æŒ `query_type` ç‚º "specific_model"
- å¦‚æœåªæœ‰ç³»åˆ—é¡å‹ï¼Œè¨­å®šç‚º "model_type"
- é€™é«”ç¾äº†å…·é«”å‹è™Ÿå„ªå…ˆæ–¼ç³»åˆ—é¡å‹çš„åŸå‰‡

**ç¬¬å››éšæ®µ: æ„åœ–é—œéµå­—åŒ¹é… (ç¬¬946-955è¡Œ)**
```python
query_lower = query.lower()

for intent_name, intent_config in self.intent_keywords.items():
    keywords = intent_config.get("keywords", [])
    if any(keyword.lower() in query_lower for keyword in keywords):
        result["intent"] = intent_name
        logging.info(f"æª¢æ¸¬åˆ°æ„åœ– '{intent_name}': {intent_config.get('description', '')}")
        break
```

**éš±å–»**: å¿ƒç†å­¸å®¶å°ç…§æ‰‹å†Šä¸­çš„å„ç¨®è¡Œç‚ºæ¨¡å¼ï¼Œæ‰¾åˆ°èˆ‡æ‚£è€…è©±èªæœ€åŒ¹é…çš„å¿ƒç†ç‹€æ…‹æè¿°ã€‚

**åŒ¹é…ç®—æ³•åˆ†æ:**
- ä½¿ç”¨å­—ä¸²åŒ…å«æª¢æŸ¥ (`keyword in query_lower`)
- æ¡ç”¨çŸ­è·¯é‚è¼¯ (`any()` å‡½æ•¸)ï¼Œä¸€æ—¦æ‰¾åˆ°åŒ¹é…å°±åœæ­¢
- å„ªå…ˆåŒ¹é…åœ¨é…ç½®æ–‡ä»¶ä¸­æ’åºè¼ƒå‰çš„æ„åœ–é¡å‹

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: å…·é«”å‹è™Ÿæ¯”è¼ƒæŸ¥è©¢**
```python
query = "æ¯”è¼ƒ AG958 å’Œ APX958 çš„ CPU æ€§èƒ½"

result = service._parse_query_intent(query)

# æœŸæœ›çµæœ
expected = {
    "modelnames": ["AG958", "APX958"],
    "modeltypes": [],
    "intent": "comparison",  # å› ç‚ºåŒ…å«"æ¯”è¼ƒ"é—œéµå­—
    "query_type": "specific_model"
}

assert result == expected
```

**ç¯„ä¾‹ 2: ç³»åˆ—æŸ¥è©¢**
```python
query = "958 ç³»åˆ—çš„æ‰€æœ‰ç­†é›»æœ‰ä»€éº¼ GPU é¸é …ï¼Ÿ"

result = service._parse_query_intent(query)

# æœŸæœ›çµæœ
expected = {
    "modelnames": [],
    "modeltypes": ["958"],
    "intent": "gpu",  # å› ç‚ºåŒ…å«"GPU"é—œéµå­— 
    "query_type": "model_type"
}

assert result == expected
```

**ç¯„ä¾‹ 3: æ¨¡ç³Šéœ€æ±‚æŸ¥è©¢**
```python
query = "æˆ‘æƒ³è¦ä¸€å°é©åˆè¾¦å…¬çš„ç­†é›»ï¼Œé‡é‡è¦è¼•ä¸€é»"

result = service._parse_query_intent(query)

# æœŸæœ›çµæœ
expected = {
    "modelnames": [],
    "modeltypes": [],
    "intent": "portability",  # å› ç‚ºåŒ…å«"é‡é‡"ã€"è¼•"é—œéµå­—
    "query_type": "unknown"  # æ²’æœ‰å…·é«”å‹è™Ÿæˆ–ç³»åˆ—
}

assert result == expected
# é€™ç¨®æŸ¥è©¢é€šå¸¸æœƒè§¸ç™¼å¤šè¼ªå°è©±
```

**ç¯„ä¾‹ 4: è¤‡åˆæŸ¥è©¢ (å‹è™Ÿ + ç³»åˆ—)**
```python
query = "AG958 å’Œ 958 ç³»åˆ—å…¶ä»–å‹è™Ÿçš„è¨˜æ†¶é«”æ¯”è¼ƒ"

result = service._parse_query_intent(query)

# æœŸæœ›çµæœ - å…·é«”å‹è™Ÿå„ªå…ˆ
expected = {
    "modelnames": ["AG958"],
    "modeltypes": ["958"],  # ä¹Ÿæœƒè¨˜éŒ„ç³»åˆ—ä¿¡æ¯
    "intent": "memory",  # å› ç‚ºåŒ…å«"è¨˜æ†¶é«”"é—œéµå­—
    "query_type": "specific_model"  # å„ªå…ˆç´šçµ¦å…·é«”å‹è™Ÿ
}

assert result == expected
```

**ç¯„ä¾‹ 5: ç„¡æ³•è­˜åˆ¥çš„æŸ¥è©¢**
```python
query = "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°£ä¸éŒ¯"

result = service._parse_query_intent(query)

# æœŸæœ›çµæœ
expected = {
    "modelnames": [],
    "modeltypes": [],
    "intent": "general",  # ä¿æŒé è¨­å€¼
    "query_type": "unknown"
}

assert result == expected
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `query_keywords.json` çš„æ·±åº¦æ•´åˆ:**

**é—œéµå­—åŒ¹é…å¯¦ä¾‹:**
```json
{
  "intent_keywords": {
    "comparison": {
      "keywords": ["æ¯”è¼ƒ", "æ¯”è¾ƒ", "compare", "å·®ç•°", "ä¸åŒ"],
      "description": "æ¯”è¼ƒç›¸é—œæŸ¥è©¢"
    },
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor", "ryzen"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    },
    "portability": {
      "keywords": ["é‡é‡", "è¼•ä¾¿", "weight", "portable", "æ”œå¸¶"],
      "description": "é‡é‡å’Œä¾¿æ”œæ€§ç›¸é—œæŸ¥è©¢"
    }
  }
}
```

**åŒ¹é…å„ªå…ˆç´šåˆ†æ:**
1. é…ç½®æ–‡ä»¶ä¸­çš„é †åºæ±ºå®šåŒ¹é…å„ªå…ˆç´š
2. ä¸€æ—¦æ‰¾åˆ°åŒ¹é…ï¼Œç«‹å³åœæ­¢æœç´¢
3. å¦‚æœå¤šå€‹æ„åœ–éƒ½æœ‰åŒ¹é…çš„é—œéµå­—ï¼Œåªæœƒé¸æ“‡ç¬¬ä¸€å€‹

**èˆ‡ `entity_patterns.json` çš„é–“æ¥é—œä¿‚:**
é›–ç„¶æ­¤å‡½æ•¸ä¸ç›´æ¥ä½¿ç”¨ `entity_patterns.json`ï¼Œä½†å®ƒèª¿ç”¨çš„å­å‡½æ•¸æœƒä½¿ç”¨ï¼š
```python
# _check_query_contains_modelname() æœƒä½¿ç”¨å¯¦é«”è­˜åˆ¥è¦å‰‡
contains_modelname, found_modelnames = self._check_query_contains_modelname(query)
```

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ”¹é€²æ„åœ–è­˜åˆ¥æº–ç¢ºæ€§:**

1. **åŠ æ¬ŠåŒ¹é…æ©Ÿåˆ¶:**
```python
def _parse_query_intent_weighted(self, query: str) -> dict:
    query_lower = query.lower()
    intent_scores = {}
    
    for intent_name, intent_config in self.intent_keywords.items():
        score = 0
        keywords = intent_config.get("keywords", [])
        
        for keyword in keywords:
            if keyword.lower() in query_lower:
                # æ ¹æ“šé—œéµå­—é•·åº¦å’Œå‡ºç¾ä½ç½®åŠ æ¬Š
                weight = len(keyword) * (1.0 if query_lower.startswith(keyword) else 0.8)
                score += weight
        
        if score > 0:
            intent_scores[intent_name] = score
    
    # é¸æ“‡å¾—åˆ†æœ€é«˜çš„æ„åœ–
    if intent_scores:
        best_intent = max(intent_scores.keys(), key=lambda k: intent_scores[k])
        result["intent"] = best_intent
```

2. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥åŒ¹é…:**
```python
def _parse_query_intent_contextual(self, query: str, previous_queries: List[str] = None) -> dict:
    # è€ƒæ…®å‰å¹¾æ¬¡æŸ¥è©¢çš„ä¸Šä¸‹æ–‡
    if previous_queries:
        context_keywords = []
        for prev_query in previous_queries[-3:]:  # åªè€ƒæ…®æœ€è¿‘3æ¬¡æŸ¥è©¢
            context_keywords.extend(self._extract_keywords(prev_query))
        
        # å¦‚æœç•¶å‰æŸ¥è©¢æ¨¡ç³Šï¼Œä½†ä¸Šä¸‹æ–‡æ¸…æ™°ï¼Œå‰‡ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯
        if result["query_type"] == "unknown" and context_keywords:
            result["intent"] = self._infer_intent_from_context(context_keywords)
```

3. **æ¨¡ç³ŠåŒ¹é…æ”¯æ´:**
```python
from difflib import SequenceMatcher

def _fuzzy_match_intent(self, query: str) -> str:
    query_lower = query.lower()
    best_match = "general"
    best_score = 0.0
    
    for intent_name, intent_config in self.intent_keywords.items():
        for keyword in intent_config.get("keywords", []):
            # ä½¿ç”¨åºåˆ—åŒ¹é…ç®—æ³•
            similarity = SequenceMatcher(None, query_lower, keyword.lower()).ratio()
            if similarity > 0.8 and similarity > best_score:
                best_match = intent_name
                best_score = similarity
    
    return best_match
```

**æ€§èƒ½å„ªåŒ–ç­–ç•¥:**

1. **é—œéµå­—é è™•ç†:**
```python
def __init__(self):
    # åœ¨åˆå§‹åŒ–æ™‚é è™•ç†é—œéµå­—
    self.processed_keywords = {}
    for intent_name, intent_config in self.intent_keywords.items():
        self.processed_keywords[intent_name] = [
            keyword.lower() for keyword in intent_config.get("keywords", [])
        ]
```

2. **æ­£å‰‡è¡¨é”å¼å„ªåŒ–:**
```python
import re

def __init__(self):
    # ç·¨è­¯æ­£å‰‡è¡¨é”å¼ä»¥æé«˜åŒ¹é…é€Ÿåº¦
    self.intent_patterns = {}
    for intent_name, intent_config in self.intent_keywords.items():
        keywords = intent_config.get("keywords", [])
        pattern = r'\b(' + '|'.join(re.escape(kw) for kw in keywords) + r')\b'
        self.intent_patterns[intent_name] = re.compile(pattern, re.IGNORECASE)
```

**å¸¸è¦‹é™·é˜±å’Œè§£æ±ºæ–¹æ¡ˆ:**

1. **é—œéµå­—è¡çª:**
   - å•é¡Œ: "cpu" å’Œ "gpu" éƒ½åŒ…å« "pu"
   - è§£æ±º: ä½¿ç”¨å®Œæ•´è©åŒ¹é…ï¼Œè€Œä¸æ˜¯å­å­—ä¸²åŒ¹é…

2. **å„ªå…ˆç´šå•é¡Œ:**
   - å•é¡Œ: é€šç”¨é—œéµå­—è¦†è“‹å°ˆç”¨é—œéµå­—
   - è§£æ±º: æŒ‰é—œéµå­—é•·åº¦æ’åºï¼Œé•·é—œéµå­—å„ªå…ˆ

3. **èªè¨€æ··ç”¨:**
   - å•é¡Œ: ç”¨æˆ¶æ··ç”¨ä¸­è‹±æ–‡
   - è§£æ±º: é—œéµå­—é…ç½®åŒ…å«å¤šèªè¨€ç‰ˆæœ¬

---

## ğŸ¨ è¡¨æ ¼è—è¡“èˆ‡æ ¼å¼åŒ–é¡

### 6. `_create_beautiful_markdown_table()` - è—è¡“å®¶ç´šè¡¨æ ¼è¨­è¨ˆå¤§å¸«

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½è¿½æ±‚å®Œç¾çš„å®¤å…§è¨­è¨ˆå¸«ï¼Œèƒ½å°‡é›œäº‚çš„æ•¸æ“šç¾åŒ–æˆè³å¿ƒæ‚…ç›®çš„è¡¨æ ¼å±•ç¤º
- **æ ¸å¿ƒä½¿å‘½**: å°‡å„ç¨®æ ¼å¼çš„æ¯”è¼ƒæ•¸æ“šè½‰æ›ç‚ºç¾è§€çš„ Markdown è¡¨æ ¼æ ¼å¼
- **é‡è¦ç­‰ç´š**: â­â­â­â­ (ç›´æ¥å½±éŸ¿ç”¨æˆ¶é«”é©—å’Œæ•¸æ“šå¯è®€æ€§)
- **èª¿ç”¨é »ç‡**: é«˜ (æ¯æ¬¡éœ€è¦å±•ç¤ºæ¯”è¼ƒè¡¨æ ¼æ™‚)
- **è¤‡é›œåº¦**: æ¥µè¤‡é›œ (è™•ç†å¤šç¨®æ•¸æ“šæ ¼å¼å’Œé‚Šç•Œæƒ…æ³)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def _create_beautiful_markdown_table(self, comparison_table: list | dict, model_names: list) -> str:
    # è¼¸å…¥: æ¯”è¼ƒè¡¨æ ¼æ•¸æ“š (å¤šç¨®æ ¼å¼) + å‹è™Ÿåç¨±åˆ—è¡¨
    # è¼¸å‡º: ç¾åŒ–çš„ Markdown è¡¨æ ¼å­—ä¸²
```

**è¼¸å…¥åƒæ•¸è©³è§£:**

1. **`comparison_table: list | dict`** - æ”¯æ´å¤šç¨®æ•¸æ“šæ ¼å¼:
   ```python
   # æ ¼å¼1: List of Dicts (æ¨™æº–æ ¼å¼)
   [
       {"feature": "CPU", "AG958": "Ryzen 7", "APX958": "Ryzen 9"},
       {"feature": "GPU", "AG958": "Radeon", "APX958": "RTX"}
   ]
   
   # æ ¼å¼2: Dict of Lists (éœ€è¦è½‰ç½®)
   {
       "Feature": ["CPU", "GPU"],
       "AG958": ["Ryzen 7", "Radeon"],
       "APX958": ["Ryzen 9", "RTX"]
   }
   
   # æ ¼å¼3: Simple Dict (å–®è¡Œå°æ¯”)
   {"ç‰¹å¾": "CPUæ€§èƒ½", "AG958": "é«˜", "APX958": "æ¥µé«˜"}
   ```

2. **`model_names: list`** - å‹è™Ÿåç¨±åˆ—è¡¨
   ```python
   ["AG958", "APX958"]  # ç”¨æ–¼ç¢ºå®šè¡¨æ ¼åˆ—é †åº
   ```

**è¼¸å‡ºçµæœè©³è§£:**
```markdown
| **è¦æ ¼é …ç›®** | **AG958** | **APX958** |
| --- | --- | --- |
| **CPU** | Ryzen 7 | Ryzen 9 |
| **GPU** | Radeon | RTX |
```

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: å­—å…¸æ ¼å¼æ™ºèƒ½è­˜åˆ¥èˆ‡è½‰æ› (ç¬¬230-284è¡Œ)**

**å­éšæ®µ 1A: æ¨¡å‹æ¬„ä½è­˜åˆ¥**
```python
if isinstance(comparison_table, dict):
    model_key = None
    for key in comparison_table.keys():
        if key.lower() in ["model", "device model", "modelname", "model_type"]:
            model_key = key
            break
```

**éš±å–»**: è¨­è¨ˆå¸«æª¢æŸ¥åŸå§‹ææ–™ï¼Œè­˜åˆ¥å‡ºå“ªå€‹æ˜¯ã€Œç”¢å“åç¨±æ¨™ç±¤ã€ã€‚

**å­éšæ®µ 1B: æœ‰æ¨¡å‹æ¬„ä½çš„è½‰ç½®è™•ç†**
```python
if model_key:
    models = comparison_table[model_key]
    spec_keys = [k for k in comparison_table.keys() if k != model_key]
    new_table = []
    for spec in spec_keys:
        row = {"feature": spec}
        for idx, model in enumerate(models):
            value = comparison_table[spec][idx] if idx < len(comparison_table[spec]) else "N/A"
            row[model] = value
        new_table.append(row)
```

**è½‰æ›ç¯„ä¾‹:**
```python
# è¼¸å…¥ (Dict of Lists):
{
    "Model": ["AG958", "APX958"],
    "CPU": ["Ryzen 7", "Ryzen 9"],  
    "GPU": ["Radeon", "RTX"]
}

# è½‰æ›å¾Œ (List of Dicts):
[
    {"feature": "CPU", "AG958": "Ryzen 7", "APX958": "Ryzen 9"},
    {"feature": "GPU", "AG958": "Radeon", "APX958": "RTX"}
]
```

**å­éšæ®µ 1C: ç°¡å–®å­—å…¸æ ¼å¼è™•ç† (ç¬¬269-283è¡Œ)**
```python
else:
    # è™•ç†ç°¡å–®çš„å­—å…¸æ ¼å¼ï¼š{"ç‰¹å¾": "å¯¹æ¯”", "AG958": "v1.0", "APX958": "v2.0"}
    keys = list(comparison_table.keys())
    if len(keys) >= 2:
        feature_key = keys[0]
        model_keys = keys[1:]
        
        row = {"feature": comparison_table[feature_key]}
        for model_key in model_keys:
            row[model_key] = comparison_table[model_key]
        
        comparison_table = [row]
        model_names = model_keys
```

**ç¬¬äºŒéšæ®µ: æ ¼å¼é©—è­‰èˆ‡éŒ¯èª¤è™•ç† (ç¬¬285-288è¡Œ)**
```python
if not isinstance(comparison_table, list):
    logging.error(f"comparison_table æ ¼å¼ä¸æ­£ç¢º: {type(comparison_table)}")
    return "è¡¨æ ¼æ ¼å¼éŒ¯èª¤"
```

**éš±å–»**: è¨­è¨ˆå¸«æª¢æŸ¥ææ–™æ˜¯å¦å·²ç¶“æº–å‚™å¦¥ç•¶ï¼Œå¦‚æœé‚„æ˜¯ä¸ç¬¦åˆè¦æ±‚å°±æ”¾æ£„é€™æ¬¡è¨­è¨ˆã€‚

**ç¬¬ä¸‰éšæ®µ: Markdown è¡¨æ ¼ç”Ÿæˆ (ç¬¬290-309è¡Œ)**
```python
# ç”¢ç”Ÿ markdown è¡¨æ ¼
header = "| **è¦æ ¼é …ç›®** |" + "".join([f" **{name}** |" for name in model_names])
separator = "| --- |" + " --- |" * len(model_names)
rows = []
for row in comparison_table:
    feature = row.get("feature", "N/A")
    row_str = f"| **{feature}** |"
    for model_name in model_names:
        value = row.get(model_name, "N/A")
        value_str = str(value)
        if len(value_str) > 50:
            value_str = value_str[:47] + "..."
        row_str += f" {value_str} |"
    rows.append(row_str)
```

**ç¾åŒ–ç´°ç¯€åˆ†æ:**
1. **æ¨™é¡Œç²—é«”åŒ–**: ä½¿ç”¨ `**æ–‡å­—**` èªæ³•
2. **é•·æ–‡å­—æˆªæ–·**: è¶…é 50 å­—ç¬¦çš„å…§å®¹æœƒè¢«æˆªæ–·ä¸¦åŠ ä¸Š "..."
3. **ç¼ºå¤±å€¼è™•ç†**: ä½¿ç”¨ "N/A" å¡«å……ç©ºç™½è³‡æ–™
4. **å°é½Šè™•ç†**: é€šéåˆ†éš”ç¬¦ç¢ºä¿è¡¨æ ¼å°é½Š

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æ¨™æº– List of Dicts æ ¼å¼**
```python
comparison_table = [
    {"feature": "CPU", "AG958": "AMD Ryzenâ„¢ 7 6800H", "APX958": "AMD Ryzenâ„¢ 9 6900HX"},
    {"feature": "GPU", "AG958": "AMD Radeonâ„¢ 680M", "APX958": "NVIDIA RTX 3070"}
]
model_names = ["AG958", "APX958"]

result = service._create_beautiful_markdown_table(comparison_table, model_names)

expected = """| **è¦æ ¼é …ç›®** | **AG958** | **APX958** |
| --- | --- | --- |
| **CPU** | AMD Ryzenâ„¢ 7 6800H | AMD Ryzenâ„¢ 9 6900HX |
| **GPU** | AMD Radeonâ„¢ 680M | NVIDIA RTX 3070 |"""

assert result == expected
```

**ç¯„ä¾‹ 2: Dict of Lists æ ¼å¼è‡ªå‹•è½‰æ›**
```python
comparison_table = {
    "Feature": ["CPU", "Memory", "Storage"],
    "AG958": ["Ryzen 7 6800H", "16GB DDR5", "512GB NVMe"],
    "APX958": ["Ryzen 9 6900HX", "32GB DDR5", "1TB NVMe"]
}
model_names = ["AG958", "APX958"]  # æœƒè¢«è‡ªå‹•æ›´æ–°

result = service._create_beautiful_markdown_table(comparison_table, model_names)

# æœŸæœ›çµæœ: è‡ªå‹•è½‰ç½®ç‚ºæ¨™æº–æ ¼å¼
assert "**CPU**" in result
assert "Ryzen 7 6800H" in result
assert "32GB DDR5" in result
```

**ç¯„ä¾‹ 3: ç°¡å–®å­—å…¸æ ¼å¼è™•ç†**
```python
comparison_table = {
    "æ¯”è¼ƒé …ç›®": "æ•´é«”æ€§èƒ½è©•åˆ†",
    "AG958": "85åˆ†",
    "APX958": "92åˆ†"
}
model_names = ["AG958", "APX958"]

result = service._create_beautiful_markdown_table(comparison_table, model_names)

expected = """| **è¦æ ¼é …ç›®** | **AG958** | **APX958** |
| --- | --- | --- |
| **æ•´é«”æ€§èƒ½è©•åˆ†** | 85åˆ† | 92åˆ† |"""

assert result == expected
```

**ç¯„ä¾‹ 4: é•·æ–‡å­—æˆªæ–·è™•ç†**
```python
comparison_table = [
    {
        "feature": "è©³ç´°è¦æ ¼",
        "AG958": "é€™æ˜¯ä¸€å€‹éå¸¸è©³ç´°çš„è¦æ ¼æè¿°ï¼ŒåŒ…å«äº†å¤§é‡çš„æŠ€è¡“ç´°ç¯€å’Œåƒæ•¸ä¿¡æ¯ï¼Œé è¶…é50å€‹å­—ç¬¦çš„é™åˆ¶",
        "APX958": "ç°¡çŸ­æè¿°"
    }
]
model_names = ["AG958", "APX958"]

result = service._create_beautiful_markdown_table(comparison_table, model_names)

# é©—è­‰é•·æ–‡å­—è¢«æˆªæ–·
assert "é€™æ˜¯ä¸€å€‹éå¸¸è©³ç´°çš„è¦æ ¼æè¿°ï¼ŒåŒ…å«äº†å¤§é‡çš„æŠ€è¡“ç´°ç¯€å’Œåƒæ•¸ä¿¡æ¯ï¼Œé è¶…é50..." in result
assert "ç°¡çŸ­æè¿°" in result
```

**ç¯„ä¾‹ 5: éŒ¯èª¤æ ¼å¼è™•ç†**
```python
# ç„¡æ•ˆçš„è¼¸å…¥æ ¼å¼
comparison_table = "é€™ä¸æ˜¯æœ‰æ•ˆçš„è¡¨æ ¼æ•¸æ“š"
model_names = ["AG958", "APX958"]

result = service._create_beautiful_markdown_table(comparison_table, model_names)

assert result == "è¡¨æ ¼æ ¼å¼éŒ¯èª¤"
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡å…¶ä»–æ ¼å¼åŒ–å‡½æ•¸çš„å”ä½œ:**
```python
# åœ¨ _format_response_with_beautiful_table() ä¸­çš„èª¿ç”¨
beautiful_table = self._create_beautiful_markdown_table(comparison_table, model_names)

# å¦‚æœç¾åŒ–å¤±æ•—ï¼Œæœƒå›é€€åˆ°ç°¡å–®æ ¼å¼
if beautiful_table == "è¡¨æ ¼æ ¼å¼éŒ¯èª¤":
    simple_table = self._create_simple_markdown_table(comparison_table, model_names)
```

**èˆ‡å‰ç«¯ JavaScript çš„é…åˆ:**
- ç”Ÿæˆçš„ Markdown æœƒè¢«å‰ç«¯çš„ `marked.js` æˆ–è‡ªè¨‚è§£æå™¨è™•ç†
- è¡¨æ ¼æœƒè¢«è½‰æ›ç‚º HTML `<table>` å…ƒç´ 
- CSS æ¨£å¼æœƒé€²ä¸€æ­¥ç¾åŒ–è¡¨æ ¼å¤–è§€

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ“´å±•è¡¨æ ¼æ ¼å¼æ”¯æ´:**

1. **æ·»åŠ æ–°çš„æ•¸æ“šæ ¼å¼è­˜åˆ¥:**
```python
def _create_beautiful_markdown_table(self, comparison_table, model_names):
    if isinstance(comparison_table, dict):
        # ç¾æœ‰æ ¼å¼è™•ç†...
        
        # æ–°å¢: è™•ç†åµŒå¥—æ ¼å¼
        elif self._is_nested_format(comparison_table):
            comparison_table = self._convert_nested_format(comparison_table)
        
        # æ–°å¢: è™•ç†çŸ©é™£æ ¼å¼  
        elif self._is_matrix_format(comparison_table):
            comparison_table = self._convert_matrix_format(comparison_table)
```

2. **å¢å¼·ç¾åŒ–åŠŸèƒ½:**
```python
def _create_beautiful_markdown_table_enhanced(self, comparison_table, model_names):
    # æ·»åŠ æ•¸æ“šé¡å‹æª¢æ¸¬å’Œæ ¼å¼åŒ–
    for row in comparison_table:
        for model_name in model_names:
            value = row.get(model_name, "N/A")
            
            # æ•¸å­—æ ¼å¼åŒ–
            if isinstance(value, (int, float)):
                value = f"{value:,.2f}" if isinstance(value, float) else f"{value:,}"
            
            # ç™¾åˆ†æ¯”æ ¼å¼åŒ–
            elif isinstance(value, str) and value.endswith('%'):
                try:
                    pct = float(value[:-1])
                    value = f"{pct:.1f}%"
                except ValueError:
                    pass
            
            row[model_name] = value
```

3. **æ·»åŠ ä¸»é¡Œæ”¯æ´:**
```python
def _create_themed_markdown_table(self, comparison_table, model_names, theme="default"):
    themes = {
        "default": {"header": "**{text}**", "cell": "{text}"},
        "minimal": {"header": "{text}", "cell": "{text}"},
        "emphasis": {"header": "***{text}***", "cell": "*{text}*"}
    }
    
    current_theme = themes.get(theme, themes["default"])
    
    # ä½¿ç”¨ä¸»é¡Œæ ¼å¼åŒ–è¡¨æ ¼...
```

**æ€§èƒ½å„ªåŒ–å»ºè­°:**

1. **é ç·¨è­¯æ¨¡æ¿:**
```python
from string import Template

class TableGenerator:
    def __init__(self):
        self.header_template = Template("| **$header** |")
        self.row_template = Template("| **$feature** | $values |")
    
    def generate_table(self, data):
        # ä½¿ç”¨é ç·¨è­¯æ¨¡æ¿åŠ é€Ÿç”Ÿæˆ
        pass
```

2. **æ•¸æ“šé è™•ç†:**
```python
def _preprocess_table_data(self, comparison_table):
    # æå‰è™•ç†æ•¸æ“šæ ¼å¼ï¼Œé¿å…åœ¨ç”Ÿæˆæ™‚é‡è¤‡è™•ç†
    if self._needs_conversion(comparison_table):
        return self._convert_once(comparison_table)
    return comparison_table
```

**æ¸¬è©¦ç­–ç•¥:**
- ğŸ§ª **æ ¼å¼æ¸¬è©¦**: æ¸¬è©¦æ‰€æœ‰æ”¯æ´çš„è¼¸å…¥æ ¼å¼
- ğŸ§ª **é‚Šç•Œæ¸¬è©¦**: æ¸¬è©¦ç©ºæ•¸æ“šã€ç•°å¸¸æ•¸æ“š
- ğŸ§ª **æ€§èƒ½æ¸¬è©¦**: æ¸¬è©¦å¤§è¡¨æ ¼çš„è™•ç†é€Ÿåº¦
- ğŸ§ª **è¦–è¦ºæ¸¬è©¦**: é©—è­‰ç”Ÿæˆçš„è¡¨æ ¼åœ¨å„ç¨®ç’°å¢ƒä¸‹çš„é¡¯ç¤ºæ•ˆæœ

---

## ğŸ¤– LLMäº¤äº’èˆ‡æ™ºèƒ½è™•ç†é¡

### 7. `chat_stream()` - å°è©±æŒ‡æ®ä¸­å¿ƒç¸½å¸ä»¤

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½ç¶“é©—è±å¯Œçš„å®¢æˆ¶æœå‹™ç¸½ç›£ï¼Œçµ±ç±Œå”èª¿å„éƒ¨é–€è³‡æºï¼Œç‚ºå®¢æˆ¶æä¾›å®Œæ•´çš„è«®è©¢é«”é©—
- **æ ¸å¿ƒä½¿å‘½**: è™•ç†ç”¨æˆ¶æŸ¥è©¢çš„å®Œæ•´æµç¨‹ï¼Œå¾æ„åœ–åˆ†æåˆ°æ•¸æ“šæª¢ç´¢ï¼Œå†åˆ° LLM æ¨ç†å’Œçµæœè¿”å›
- **é‡è¦ç­‰ç´š**: â­â­â­â­â­ (ç³»çµ±çš„æ ¸å¿ƒæ§åˆ¶ä¸­å¿ƒ)
- **èª¿ç”¨é »ç‡**: æ¥µé«˜ (æ¯æ¬¡ç”¨æˆ¶äº¤äº’éƒ½æœƒèª¿ç”¨)
- **è¤‡é›œåº¦**: æ¥µè¤‡é›œ (åŒ…å«å¤šéšæ®µæ±ºç­–å’ŒéŒ¯èª¤è™•ç†)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
async def chat_stream(self, query: str, **kwargs):
    # è¼¸å…¥: ç”¨æˆ¶æŸ¥è©¢å­—ä¸²å’Œå¯é¸åƒæ•¸
    # è¼¸å‡º: ç•°æ­¥ç”Ÿæˆå™¨ï¼Œç”¢ç”Ÿ SSE æ ¼å¼çš„ JSON æ•¸æ“šæµ
```

**è¼¸å…¥åƒæ•¸è©³è§£:**
- `query: str`: ç”¨æˆ¶çš„è‡ªç„¶èªè¨€æŸ¥è©¢
  - ç¯„ä¾‹: `"æ¯”è¼ƒ AG958 å’Œ APX958 çš„ CPU æ€§èƒ½"`
  - ç¯„ä¾‹: `"æˆ‘æƒ³è¦ä¸€å°é©åˆéŠæˆ²çš„ç­†é›»"`
  - ç¯„ä¾‹: `"è«‹åˆ—å‡ºæ‰€æœ‰NBå‹è™Ÿ"`

**è¼¸å‡ºæ ¼å¼è©³è§£:**
- ç•°æ­¥ç”Ÿæˆå™¨ï¼Œæ¯æ¬¡ `yield` ç”¢ç”Ÿ SSE æ ¼å¼å­—ä¸²
- æ•¸æ“šæ ¼å¼: `f"data: {json.dumps(response_dict, ensure_ascii=False)}\n\n"`
- éŸ¿æ‡‰é¡å‹:
  ```python
  # å¤šè¼ªå°è©±å•Ÿå‹•
  {"type": "multichat_all_questions", "questions": [...], "message": "..."}
  
  # æ¨™æº–æ¯”è¼ƒå›æ‡‰
  {"answer_summary": "...", "comparison_table": [...]}
  
  # éŒ¯èª¤å›æ‡‰
  {"answer_summary": "éŒ¯èª¤ä¿¡æ¯", "comparison_table": []}
  ```

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**éšæ®µ 0: ç³»çµ±æ¸…å–®æŸ¥è©¢æª¢æŸ¥ (ç¬¬1081-1094è¡Œ)**
```python
if self._should_list_all_models(query):
    logging.info("æª¢æ¸¬åˆ°å‹è™Ÿåˆ—è¡¨è«‹æ±‚ï¼Œè¿”å›æ‰€æœ‰å¯ç”¨å‹è™Ÿ")
    available_types_str = "\n".join([f"- {modeltype}" for modeltype in AVAILABLE_MODELTYPES])
    available_models_str = "\n".join([f"- {model}" for model in AVAILABLE_MODELNAMES])
    
    list_message = f"å¯ç”¨çš„ç³»åˆ—åŒ…æ‹¬ï¼š\n{available_types_str}\n\nå¯ç”¨çš„å‹è™ŸåŒ…æ‹¬ï¼š\n{available_models_str}\n\nè«‹é‡æ–°æå•..."
    
    list_response = {"answer_summary": list_message, "comparison_table": []}
    yield f"data: {json.dumps(list_response, ensure_ascii=False)}\n\n"
    return
```

**éš±å–»**: ç¸½å¸ä»¤é¦–å…ˆæª¢æŸ¥é€™æ˜¯å¦æ˜¯ä¸€å€‹ã€Œå…¨å“¡é›†åˆã€çš„æŒ‡ä»¤ï¼Œå¦‚æœæ˜¯ï¼Œç«‹å³èª¿é–±èŠ±åå†Šä¸¦å›å ±ã€‚

**éšæ®µ 1: å¤šè¼ªå°è©±è§¸ç™¼æª¢æŸ¥ (ç¬¬1096-1128è¡Œ)**
```python
should_start_multichat, detected_scenario = self.multichat_manager.should_activate_multichat(query)

# æ“´å±•å•†å‹™å’Œç­†é›»ç›¸é—œçš„è§¸ç™¼æ¢ä»¶
business_keywords = ["å•†å‹™", "è¾¦å…¬", "å·¥ä½œ", "ä¼æ¥­", "å•†ç”¨", "æ¥­å‹™", "è·å ´", "å…¬å¸", "æ–‡æ›¸è™•ç†", "æ–‡æ›¸", "è™•ç†"]
laptop_keywords = ["ç­†é›»", "ç­†è¨˜æœ¬", "ç­†è¨˜å‹é›»è…¦", "laptop", "notebook", "é›»è…¦", "NB"]
introduction_keywords = ["ä»‹ç´¹", "æ¨è–¦", "å»ºè­°", "é¸æ“‡", "æŒ‘é¸", "é©åˆ", "éœ€è¦"]

is_business_laptop_query = (
    any(bk in query for bk in business_keywords) and 
    any(lk in query for lk in laptop_keywords)
) or (
    any(lk in query for lk in laptop_keywords) and 
    any(ik in query for ik in introduction_keywords)
)
```

**æ±ºç­–é‚è¼¯åˆ†æ:**
1. é¦–å…ˆæª¢æŸ¥å¤šè¼ªå°è©±ç®¡ç†å™¨çš„æ¨™æº–è§¸ç™¼æ¢ä»¶
2. é¡å¤–æª¢æŸ¥å•†å‹™ç­†é›»ç›¸é—œæŸ¥è©¢
3. æª¢æŸ¥ä¸€èˆ¬æ€§çš„ç­†é›»æ¨è–¦æŸ¥è©¢
4. å¦‚æœç¬¦åˆä»»ä¸€æ¢ä»¶ï¼Œå•Ÿå‹•å•å·æ¨¡å¼

**éš±å–»**: ç¸½å¸ä»¤åˆ¤æ–·é€™å€‹æŸ¥è©¢æ˜¯å¦éœ€è¦ã€Œè©³ç´°è«®è©¢æµç¨‹ã€ï¼Œå¦‚æœå®¢æˆ¶çš„éœ€æ±‚æ¨¡ç³Šï¼Œå°±å•Ÿå‹•æ¨™æº–çš„éœ€æ±‚æ”¶é›†ç¨‹åºã€‚

**éšæ®µ 2: æŸ¥è©¢æ„åœ–è§£æ (ç¬¬1130-1156è¡Œ)**
```python
query_intent = self._parse_query_intent(query)
logging.info(f"æŸ¥è©¢æ„åœ–è§£æçµæœ: {query_intent}")

if query_intent["query_type"] == "unknown":
    # æª¢æŸ¥æ˜¯å¦æŸ¥è©¢äº†ä¸å­˜åœ¨çš„ç³»åˆ—
    potential_series = re.findall(r'\b\d{3,4}\b', query)
    non_existent_series = [s for s in potential_series if s not in AVAILABLE_MODELTYPES]
    
    if non_existent_series:
        available_types_str = "ã€".join(AVAILABLE_MODELTYPES)
        unknown_message = f"å¾ˆæŠ±æ­‰ï¼Œç›®å‰æ²’æœ‰ {non_existent_series[0]} ç³»åˆ—çš„ç­†é›»è³‡æ–™ã€‚\n\nç›®å‰å¯æŸ¥è©¢çš„ç³»åˆ—åŒ…æ‹¬ï¼š{available_types_str}..."
    else:
        unknown_message = "å¾ˆæŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç†è§£æ‚¨çš„æŸ¥è©¢ã€‚è«‹æä¾›æ›´å…·é«”çš„å•é¡Œ..."
```

**éŒ¯èª¤è™•ç†ç­–ç•¥:**
- è­˜åˆ¥ç”¨æˆ¶æŸ¥è©¢ä¸å­˜åœ¨çš„ç³»åˆ—è™Ÿ (å¦‚ 656, 777)
- æä¾›å‹å–„çš„éŒ¯èª¤ä¿¡æ¯å’Œå¯ç”¨é¸é …
- çµ¦å‡ºå…·é«”çš„æŸ¥è©¢å»ºè­°

**éšæ®µ 3: æ•¸æ“šæª¢ç´¢èˆ‡é©—è­‰ (ç¬¬1158-1188è¡Œ)**
```python
try:
    context_list_of_dicts, target_modelnames = self._get_data_by_query_type(query_intent)
    logging.info(f"æˆåŠŸè·å–æ•°æ®ï¼Œå‹å·æ•°é‡: {len(target_modelnames)}")
    
except ValueError as e:
    error_message = str(e)
    error_obj = {"answer_summary": error_message, "comparison_table": []}
    yield f"data: {json.dumps(error_obj, ensure_ascii=False)}\n\n"
    return

# æª¢æŸ¥æ•¸æ“šå¯ç”¨æ€§
has_data, missing_data_info = self._check_data_availability(context_list_of_dicts, target_modelnames, query_intent)

if not has_data:
    missing_info_str = "ã€".join(missing_data_info) if missing_data_info else "ç›¸é—œè³‡æ–™"
    no_data_message = f"æŠ±æ­‰ï¼Œ{missing_info_str}ä¸¦ç„¡ç™»è¨˜è³‡æ–™ã€‚"
    
    no_data_response = {"answer_summary": no_data_message, "comparison_table": []}
    yield f"data: {json.dumps(no_data_response, ensure_ascii=False)}\n\n"
    return
```

**æ•¸æ“šé©—è­‰æµç¨‹:**
1. å˜—è©¦æ ¹æ“šæŸ¥è©¢æ„åœ–ç²å–ç›¸é—œæ•¸æ“š
2. å¦‚æœæ•¸æ“šæª¢ç´¢å¤±æ•—ï¼Œç«‹å³è¿”å›éŒ¯èª¤ä¿¡æ¯
3. æª¢æŸ¥ç²å–çš„æ•¸æ“šæ˜¯å¦åŒ…å«ç”¨æˆ¶æŸ¥è©¢çš„ç‰¹å®šä¿¡æ¯
4. å¦‚æœç¼ºå°‘é—œéµæ•¸æ“šï¼Œè¿”å›ã€Œä¸¦ç„¡ç™»è¨˜è³‡æ–™ã€

**éšæ®µ 4: LLM æ¨ç†è™•ç† (ç¬¬1190-1260è¡Œ)**
```python
# æ§‹å»ºå¢å¼·çš„ä¸Šä¸‹æ–‡
enhanced_context = {
    "data": context_list_of_dicts,
    "query_intent": query_intent,
    "target_modelnames": target_modelnames
}

context_str = json.dumps(enhanced_context, indent=2, ensure_ascii=False)

# æ§‹å»ºæç¤ºè©
intent_info = f"""
[QUERY INTENT ANALYSIS]
Based on the query intent analysis:
- Query Type: {query_intent['query_type']}
- Intent: {query_intent['intent']}
- Target Models: {', '.join(target_modelnames)}

Focus your analysis on the specific intent and target models identified above.
"""

final_prompt = self.prompt_template.replace("{context}", context_str).replace("{query}", query)
final_prompt = final_prompt.replace("[QUERY INTENT ANALYSIS]", intent_info)

# èª¿ç”¨ LLM
response_str = self.llm_initializer.invoke(final_prompt)
```

**æç¤ºè©æ§‹å»ºç­–ç•¥:**
- åŒ…å«çµæ§‹åŒ–çš„æŸ¥è©¢æ„åœ–åˆ†æ
- æ˜ç¢ºæŒ‡å®šç›®æ¨™å‹è™Ÿå’ŒæŸ¥è©¢é¡å‹
- ç‚º LLM æä¾›æ˜ç¢ºçš„åˆ†ææ–¹å‘

**éšæ®µ 5: å›æ‡‰è§£æèˆ‡è™•ç† (ç¬¬1224-1320è¡Œ)**
```python
# è™•ç† <think> æ¨™ç±¤
think_end = response_str.find("</think>")
if think_end != -1:
    cleaned_response_str = response_str[think_end + 8:].strip()
else:
    cleaned_response_str = response_str

# æå– JSON å…§å®¹
json_start = cleaned_response_str.find("{")
json_end = cleaned_response_str.rfind("}")

if json_start != -1 and json_end != -1 and json_end > json_start:
    json_content = cleaned_response_str[json_start:json_end+1]
    
    try:
        parsed_json = json.loads(json_content)
    except json.JSONDecodeError:
        # å˜—è©¦ä¿®å¾© JSON æ ¼å¼
        fixed_json_content = self._fix_json_format(json_content)
        parsed_json = json.loads(fixed_json_content)
```

**JSON è™•ç†ç­–ç•¥:**
- è­˜åˆ¥å’Œç§»é™¤ DeepSeek æ¨¡å‹çš„æ€è€ƒæ¨™ç±¤
- ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æå– JSON å…§å®¹
- å¤šå±¤éŒ¯èª¤è™•ç†å’Œæ ¼å¼ä¿®å¾©
- æ”¯æ´éƒ¨åˆ† JSON æå–ä½œç‚ºå‚™æ´

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: æˆåŠŸçš„å‹è™Ÿæ¯”è¼ƒæŸ¥è©¢**
```python
query = "æ¯”è¼ƒ AG958 å’Œ APX958 çš„ CPU æ€§èƒ½"

# æ¨¡æ“¬ SSE æµæ¥æ”¶
responses = []
async for chunk in service.chat_stream(query):
    responses.append(chunk)

# è§£ææœ€çµ‚å›æ‡‰
final_data = json.loads(responses[-1].replace("data: ", ""))

# æœŸæœ›çµæœçµæ§‹
assert "answer_summary" in final_data
assert "comparison_table" in final_data
assert isinstance(final_data["comparison_table"], list)
assert len(final_data["comparison_table"]) > 0

# é©—è­‰è¡¨æ ¼å…§å®¹
table = final_data["comparison_table"]
assert any("CPU" in row.get("feature", "") for row in table)
assert any("AG958" in row for row in table)
assert any("APX958" in row for row in table)
```

**ç¯„ä¾‹ 2: æ¨¡ç³ŠæŸ¥è©¢è§¸ç™¼å¤šè¼ªå°è©±**
```python
query = "æˆ‘æƒ³è¦ä¸€å°é©åˆè¾¦å…¬çš„ç­†é›»"

responses = []
async for chunk in service.chat_stream(query):
    responses.append(chunk)

# è§£æå›æ‡‰
final_data = json.loads(responses[-1].replace("data: ", ""))

# æœŸæœ›è§¸ç™¼å•å·æ¨¡å¼
assert final_data["type"] == "multichat_all_questions"
assert "questions" in final_data
assert isinstance(final_data["questions"], list)
assert len(final_data["questions"]) > 0

# é©—è­‰å•é¡Œçµæ§‹
first_question = final_data["questions"][0]
assert "feature_id" in first_question
assert "question" in first_question
assert "options" in first_question
```

**ç¯„ä¾‹ 3: ä¸å­˜åœ¨å‹è™Ÿçš„éŒ¯èª¤è™•ç†**
```python
query = "777 ç³»åˆ—ç­†é›»æœ‰å“ªäº›å‹è™Ÿï¼Ÿ"

responses = []
async for chunk in service.chat_stream(query):
    responses.append(chunk)

final_data = json.loads(responses[-1].replace("data: ", ""))

# æœŸæœ›å‹å–„çš„éŒ¯èª¤ä¿¡æ¯
assert "å¾ˆæŠ±æ­‰ï¼Œç›®å‰æ²’æœ‰ 777 ç³»åˆ—çš„ç­†é›»è³‡æ–™" in final_data["answer_summary"]
assert "ç›®å‰å¯æŸ¥è©¢çš„ç³»åˆ—åŒ…æ‹¬" in final_data["answer_summary"]
assert "819" in final_data["answer_summary"]  # æ‡‰è©²åˆ—å‡ºå¯ç”¨ç³»åˆ—
```

**ç¯„ä¾‹ 4: ç³»çµ±æ¸…å–®æŸ¥è©¢**
```python
query = "è«‹åˆ—å‡ºæ‰€æœ‰NBå‹è™Ÿ"

responses = []
async for chunk in service.chat_stream(query):
    responses.append(chunk)

final_data = json.loads(responses[-1].replace("data: ", ""))

# æœŸæœ›å®Œæ•´çš„å‹è™Ÿæ¸…å–®
assert "å¯ç”¨çš„ç³»åˆ—åŒ…æ‹¬" in final_data["answer_summary"]
assert "å¯ç”¨çš„å‹è™ŸåŒ…æ‹¬" in final_data["answer_summary"]
assert "AG958" in final_data["answer_summary"]
assert "è«‹é‡æ–°æå•" in final_data["answer_summary"]
```

**ç¯„ä¾‹ 5: LLM å›æ‡‰è™•ç†éŒ¯èª¤çš„å‚™æ´**
```python
# æ¨¡æ“¬ LLM è¿”å›æ ¼å¼éŒ¯èª¤çš„å›æ‡‰
query = "AG958 çš„ CPU è¦æ ¼"

# å¦‚æœ LLM å›æ‡‰ç„¡æ³•è§£æï¼Œæ‡‰è©²ä½¿ç”¨å‚™æ´å›æ‡‰
responses = []
async for chunk in service.chat_stream(query):
    responses.append(chunk)

final_data = json.loads(responses[-1].replace("data: ", ""))

# å³ä½¿ LLM å¤±æ•—ï¼Œä¹Ÿæ‡‰è©²æœ‰åŸºæœ¬çš„å›æ‡‰
assert "answer_summary" in final_data
assert "comparison_table" in final_data

# å‚™æ´å›æ‡‰æ‡‰è©²åŸºæ–¼å¯¦éš›æ•¸æ“š
if final_data["answer_summary"].startswith("æ ¹æ“šæä¾›çš„æ•°æ®"):
    # é€™æ˜¯å‚™æ´å›æ‡‰
    assert len(final_data["comparison_table"]) > 0
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡å¤šå€‹é…ç½®æ–‡ä»¶çš„å”ä½œ:**
1. **query_keywords.json**: ç”¨æ–¼æ„åœ–è­˜åˆ¥
2. **entity_patterns.json**: ç”¨æ–¼å‹è™Ÿåç¨±æå–
3. **nb_features.json**: ç”¨æ–¼å¤šè¼ªå°è©±å•é¡Œç”Ÿæˆ
4. **sales_prompt.txt**: ç”¨æ–¼ LLM æç¤ºè©æ¨¡æ¿

**èˆ‡å…¶ä»–æœå‹™çš„æ•´åˆ:**
```python
# å¤šè¼ªå°è©±ç®¡ç†
should_start_multichat = self.multichat_manager.should_activate_multichat(query)

# æ•¸æ“šåº«æŸ¥è©¢
context_list_of_dicts, target_modelnames = self._get_data_by_query_type(query_intent)

# LLM æ¨ç†
response_str = self.llm_initializer.invoke(final_prompt)
```

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ“´å±•æŸ¥è©¢è™•ç†èƒ½åŠ›:**

1. **æ·»åŠ æ–°çš„æŸ¥è©¢é¡å‹:**
```python
async def chat_stream(self, query: str, **kwargs):
    # ç¾æœ‰é‚è¼¯...
    
    # æ–°å¢: åœ–ç‰‡æŸ¥è©¢è™•ç†
    if self._is_image_query(query):
        return await self._handle_image_query(query)
    
    # æ–°å¢: èªéŸ³æŸ¥è©¢è™•ç†  
    if self._is_voice_query(query):
        return await self._handle_voice_query(query)
```

2. **æ”¹é€²éŒ¯èª¤è™•ç†æ©Ÿåˆ¶:**
```python
async def chat_stream_with_retry(self, query: str, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            async for response in self.chat_stream(query):
                yield response
            return
        except Exception as e:
            if attempt == max_retries - 1:
                # æœ€å¾Œä¸€æ¬¡é‡è©¦å¤±æ•—ï¼Œè¿”å›ç”¨æˆ¶å‹å–„çš„éŒ¯èª¤
                error_response = {
                    "answer_summary": "å¾ˆæŠ±æ­‰ï¼Œç³»çµ±æš«æ™‚ç„¡æ³•è™•ç†æ‚¨çš„æŸ¥è©¢ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                    "comparison_table": []
                }
                yield f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n"
            else:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
```

3. **æ·»åŠ å¿«å–æ©Ÿåˆ¶:**
```python
from functools import lru_cache
import hashlib

class CachedChatStream:
    def __init__(self, service):
        self.service = service
        self.cache = {}
    
    async def chat_stream(self, query: str):
        # ç”ŸæˆæŸ¥è©¢çš„é›œæ¹Šå€¼
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        # æª¢æŸ¥å¿«å–
        if query_hash in self.cache:
            cached_response = self.cache[query_hash]
            yield f"data: {json.dumps(cached_response, ensure_ascii=False)}\n\n"
            return
        
        # åŸ·è¡ŒæŸ¥è©¢ä¸¦å¿«å–çµæœ
        responses = []
        async for chunk in self.service.chat_stream(query):
            responses.append(chunk)
            yield chunk
        
        # å„²å­˜åˆ°å¿«å–
        if responses:
            final_response = json.loads(responses[-1].replace("data: ", ""))
            self.cache[query_hash] = final_response
```

**æ€§èƒ½ç›£æ§å»ºè­°:**
- ğŸ“Š è¨˜éŒ„æ¯å€‹éšæ®µçš„åŸ·è¡Œæ™‚é–“
- ğŸ“Š ç›£æ§ LLM èª¿ç”¨çš„æˆåŠŸç‡å’Œå»¶é²
- ğŸ“Š è¿½è¹¤å¤šè¼ªå°è©±çš„è§¸ç™¼ç‡
- ğŸ“Š åˆ†æå¸¸è¦‹çš„æŸ¥è©¢æ¨¡å¼å’ŒéŒ¯èª¤é¡å‹

---

## ğŸ­ å¤šè¼ªå°è©±ç®¡ç†é¡

### 8. `get_all_questions()` - å•å·è¨­è¨ˆå¤§å¸«

#### ğŸ­ å‡½æ•¸èº«ä»½è­‰
- **å‡½æ•¸è§’è‰²**: åƒä¸€ä½ç¶“é©—è±å¯Œçš„å¸‚å ´èª¿ç ”å°ˆå®¶ï¼Œèƒ½å¤ è¨­è¨ˆå‡ºç²¾æº–çš„å•å·ä¾†äº†è§£å®¢æˆ¶çš„çœŸæ­£éœ€æ±‚
- **æ ¸å¿ƒä½¿å‘½**: æ ¹æ“šç”¨æˆ¶æŸ¥è©¢å’Œå ´æ™¯ï¼Œç”Ÿæˆå®Œæ•´çš„å¤šè¼ªå°è©±å•å·ï¼Œç”¨æ–¼æ”¶é›†ç”¨æˆ¶çš„ç­†é›»éœ€æ±‚åå¥½
- **é‡è¦ç­‰ç´š**: â­â­â­â­ (å½±éŸ¿å€‹æ€§åŒ–æ¨è–¦çš„æº–ç¢ºæ€§)
- **èª¿ç”¨é »ç‡**: ä¸­ç­‰ (ç•¶æª¢æ¸¬åˆ°æ¨¡ç³ŠæŸ¥è©¢æ™‚è§¸ç™¼)
- **è¤‡é›œåº¦**: è¤‡é›œ (éœ€è¦å‹•æ…‹ç”Ÿæˆå’Œå ´æ™¯é©é…)

#### ğŸ“Š è¼¸å…¥è¼¸å‡ºè§£å‰–

```python
def get_all_questions(self, query: str = "", scenario: str = None) -> dict:
    # è¼¸å…¥: ç”¨æˆ¶æŸ¥è©¢å­—ä¸² + å¯é¸çš„å ´æ™¯é¡å‹
    # è¼¸å‡º: å®Œæ•´çš„å•å·çµæ§‹å­—å…¸
```

**è¼¸å…¥åƒæ•¸è©³è§£:**
- `query: str`: ç”¨æˆ¶çš„åŸå§‹æŸ¥è©¢ (ç”¨æ–¼ä¸Šä¸‹æ–‡åˆ†æ)
  - ç¯„ä¾‹: `"æˆ‘æƒ³è¦ä¸€å°é©åˆè¾¦å…¬çš„ç­†é›»"`
  - ç¯„ä¾‹: `"æ¨è–¦ä¸€å°éŠæˆ²ç­†é›»"`
- `scenario: str`: å ´æ™¯é¡å‹ (å¯é¸)
  - å€¼: `"business"`, `"gaming"`, `"general"` ç­‰
  - å½±éŸ¿å•é¡Œçš„å„ªå…ˆé †åºå’Œå…§å®¹

**è¼¸å‡ºçµæœè©³è§£:**
```python
{
    "type": "multichat_all_questions",
    "message": "è«‹å›ç­”ä»¥ä¸‹å•é¡Œï¼Œå¹«åŠ©æˆ‘ç‚ºæ‚¨æ¨è–¦æœ€é©åˆçš„ç­†é›»ï¼š",
    "total_questions": 7,
    "questions": [
        {
            "step": 1,
            "feature_id": "cpu",
            "question": "è«‹å•æ‚¨å°è™•ç†å™¨(CPU)æœ‰ä»€éº¼åå¥½å—ï¼Ÿ",
            "options": [
                {
                    "option_id": "high_performance", 
                    "label": "ğŸš€ é«˜æ•ˆèƒ½è™•ç†å™¨",
                    "description": "é©åˆéŠæˆ²ã€å‰µä½œã€å¤šå·¥è™•ç†"
                }
            ]
        }
    ]
}
```

#### ğŸ”„ å¯¦ä½œé‚è¼¯æ·±åº¦è§£æ

**ç¬¬ä¸€éšæ®µ: è¼‰å…¥å•é¡Œé…ç½® (ç¬¬2398-2425è¡Œ)**
```python
def get_all_questions(self, query: str = "", scenario: str = None) -> dict:
    try:
        logging.info(f"ç”Ÿæˆæ‰€æœ‰å•é¡Œï¼ŒæŸ¥è©¢: '{query}', å ´æ™¯: {scenario}")
        
        # è¼‰å…¥å¤šè¼ªå°è©±é…ç½®
        if not hasattr(self, '_nb_features_config'):
            config_path = "libs/services/sales_assistant/multichat/nb_features.json"
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    self._nb_features_config = json.load(f)
                    logging.info(f"æˆåŠŸè¼‰å…¥å•é¡Œé…ç½®: {config_path}")
            except Exception as e:
                logging.error(f"è¼‰å…¥å•é¡Œé…ç½®å¤±æ•—: {e}")
                return {"error": "ç„¡æ³•è¼‰å…¥å•é¡Œé…ç½®"}
        
        nb_features = self._nb_features_config.get("nb_features", {})
        feature_priorities = self._nb_features_config.get("feature_priorities", {})
```

**éš±å–»**: å•å·è¨­è¨ˆå¸«æ‰“é–‹å·¥å…·ç®±ï¼Œå–å‡ºå„ç¨®å•é¡Œæ¨¡æ¿å’Œå„ªå…ˆç´šæŒ‡å—ï¼Œç‚ºç‰¹å®šå ´æ™¯å®šåˆ¶æœ€é©åˆçš„å•å·ã€‚

**é…ç½®è¼‰å…¥ç­–ç•¥:**
- ä½¿ç”¨å¿«å–æ©Ÿåˆ¶ (`hasattr` æª¢æŸ¥)ï¼Œé¿å…é‡è¤‡æª”æ¡ˆè®€å–
- å„ªé›…çš„éŒ¯èª¤è™•ç†ï¼Œé…ç½®è¼‰å…¥å¤±æ•—æ™‚è¿”å›éŒ¯èª¤ä¿¡æ¯
- æ”¯æ´çµæ§‹åŒ–çš„å•é¡Œé…ç½®å’Œå„ªå…ˆç´šè¨­å®š

**ç¬¬äºŒéšæ®µ: å ´æ™¯æª¢æ¸¬èˆ‡å„ªå…ˆç´šæ±ºå®š (ç¬¬2426-2445è¡Œ)**
```python
# å ´æ™¯æª¢æ¸¬é‚è¼¯
if not scenario:
    query_lower = query.lower()
    if any(keyword in query_lower for keyword in ["éŠæˆ²", "gaming", "é›»ç«¶", "é«˜æ•ˆèƒ½"]):
        scenario = "gaming"
    elif any(keyword in query_lower for keyword in ["å•†å‹™", "è¾¦å…¬", "å·¥ä½œ", "å•†ç”¨"]):
        scenario = "business"  
    elif any(keyword in query_lower for keyword in ["å­¸ç”Ÿ", "å­¸ç¿’", "ä¸Šèª²", "ä¾¿å®œ"]):
        scenario = "study"
    elif any(keyword in query_lower for keyword in ["å‰µä½œ", "è¨­è¨ˆ", "å½±ç‰‡", "ç¹ªåœ–"]):
        scenario = "creation"
    else:
        scenario = "general"

logging.info(f"æª¢æ¸¬åˆ°å ´æ™¯é¡å‹: {scenario}")

# æ ¹æ“šå ´æ™¯ç²å–å•é¡Œå„ªå…ˆé †åº
priority_order = feature_priorities.get(scenario, feature_priorities.get("general", []))
```

**å ´æ™¯è­˜åˆ¥æ¼”ç®—æ³•:**
- ä½¿ç”¨é—œéµå­—åŒ¹é…é€²è¡Œå ´æ™¯åˆ†é¡
- æ”¯æ´å¤šç¨®é å®šç¾©å ´æ™¯ï¼šéŠæˆ²ã€å•†å‹™ã€å­¸ç¿’ã€å‰µä½œã€é€šç”¨
- æ¯ç¨®å ´æ™¯æœ‰ä¸åŒçš„å•é¡Œå„ªå…ˆé †åº

**å ´æ™¯å„ªå…ˆç´šç¯„ä¾‹:**
```json
{
  "feature_priorities": {
    "gaming": ["gpu", "cpu", "memory", "storage", "price", "size", "weight"],
    "business": ["weight", "cpu", "price", "size", "memory", "storage", "gpu"],
    "study": ["price", "weight", "cpu", "memory", "size", "storage", "gpu"]
  }
}
```

**ç¬¬ä¸‰éšæ®µ: å•é¡Œå‹•æ…‹ç”Ÿæˆ (ç¬¬2446-2470è¡Œ)**
```python
questions = []
step_counter = 1

for feature_id in priority_order:
    if feature_id in nb_features:
        feature_config = nb_features[feature_id]
        
        question_data = {
            "step": step_counter,
            "feature_id": feature_id,
            "question": feature_config.get("question_template", f"é—œæ–¼{feature_config.get('name', feature_id)}çš„åå¥½ï¼Ÿ"),
            "options": []
        }
        
        # è™•ç†é¸é …
        for option in feature_config.get("options", []):
            question_data["options"].append({
                "option_id": option.get("option_id"),
                "label": option.get("label", ""),
                "description": option.get("description", "")
            })
        
        questions.append(question_data)
        step_counter += 1
```

**å•é¡Œç”Ÿæˆé‚è¼¯:**
- æŒ‰ç…§å ´æ™¯å„ªå…ˆç´šé †åºéæ­·åŠŸèƒ½ç‰¹æ€§
- ç‚ºæ¯å€‹ç‰¹æ€§å‰µå»ºçµæ§‹åŒ–çš„å•é¡Œå°è±¡
- åŒ…å«å•é¡Œæ–‡æœ¬ã€é¸é …åˆ—è¡¨å’Œå…ƒæ•¸æ“š
- è‡ªå‹•åˆ†é…æ­¥é©Ÿç·¨è™Ÿ

**ç¬¬å››éšæ®µ: å›æ‡‰çµæ§‹æ§‹å»º (ç¬¬2472-2480è¡Œ)**
```python
return {
    "type": "multichat_all_questions",
    "message": f"è«‹å›ç­”ä»¥ä¸‹ {len(questions)} å€‹å•é¡Œï¼Œå¹«åŠ©æˆ‘ç‚ºæ‚¨æ¨è–¦æœ€é©åˆçš„ç­†é›»ï¼š",
    "total_questions": len(questions),
    "questions": questions,
    "scenario": scenario,
    "query_context": query
}
```

#### ğŸ¯ å¯¦æˆ°ç¯„ä¾‹æ¼”ç¤º

**ç¯„ä¾‹ 1: éŠæˆ²å ´æ™¯å•å·ç”Ÿæˆ**
```python
query = "æˆ‘æƒ³è¦ä¸€å°é©åˆç©éŠæˆ²çš„ç­†é›»"
scenario = None  # è®“ç³»çµ±è‡ªå‹•æª¢æ¸¬

result = service.get_all_questions(query, scenario)

# é©—è­‰å ´æ™¯æª¢æ¸¬
assert result["scenario"] == "gaming"
assert result["type"] == "multichat_all_questions"
assert result["total_questions"] > 0

# é©—è­‰å•é¡Œå„ªå…ˆé †åº (éŠæˆ²å ´æ™¯GPUå„ªå…ˆ)
questions = result["questions"]
first_question = questions[0]
assert first_question["feature_id"] in ["gpu", "cpu"]  # éŠæˆ²ç›¸é—œçš„é«˜å„ªå…ˆç´š

# é©—è­‰å•é¡Œçµæ§‹
assert "step" in first_question
assert "question" in first_question  
assert "options" in first_question
assert len(first_question["options"]) > 0

# é©—è­‰é¸é …çµæ§‹
first_option = first_question["options"][0]
assert "option_id" in first_option
assert "label" in first_option
assert "description" in first_option
```

**ç¯„ä¾‹ 2: å•†å‹™å ´æ™¯å•å·ç”Ÿæˆ**
```python
query = "æ¨è–¦ä¸€å°é©åˆå•†å‹™è¾¦å…¬çš„ç­†é›»"

result = service.get_all_questions(query)

# é©—è­‰å•†å‹™å ´æ™¯çš„å„ªå…ˆç´š (é‡é‡å’Œä¾¿æ”œæ€§å„ªå…ˆ)
assert result["scenario"] == "business"
questions = result["questions"]
first_question = questions[0]
assert first_question["feature_id"] in ["weight", "cpu", "price"]

# é©—è­‰å•é¡Œå…§å®¹é©åˆå•†å‹™å ´æ™¯
question_text = first_question["question"]
assert any(keyword in question_text for keyword in ["é‡é‡", "ä¾¿æ”œæ€§", "æ•ˆèƒ½", "åƒ¹æ ¼"])
```

**ç¯„ä¾‹ 3: é€šç”¨å ´æ™¯å•å·ç”Ÿæˆ**
```python
query = "æˆ‘éœ€è¦ä¸€å°ç­†é›»"  # éå¸¸æ¨¡ç³Šçš„æŸ¥è©¢

result = service.get_all_questions(query)

# æ‡‰è©²ä½¿ç”¨é€šç”¨å ´æ™¯
assert result["scenario"] == "general"

# é€šç”¨å ´æ™¯æ‡‰è©²æ¶µè“‹æ‰€æœ‰é‡è¦ç‰¹æ€§
questions = result["questions"]
feature_ids = [q["feature_id"] for q in questions]

# é©—è­‰åŒ…å«æ ¸å¿ƒç‰¹æ€§
expected_features = ["cpu", "gpu", "memory", "storage", "price"]
for feature in expected_features:
    assert feature in feature_ids
```

**ç¯„ä¾‹ 4: å­¸ç”Ÿå ´æ™¯å•å·ç”Ÿæˆ**
```python
query = "æˆ‘æ˜¯å­¸ç”Ÿï¼Œæƒ³è²·ä¸€å°ä¾¿å®œçš„ç­†é›»ç”¨ä¾†ä¸Šèª²"

result = service.get_all_questions(query)

# å­¸ç”Ÿå ´æ™¯æ‡‰è©²å„ªå…ˆè€ƒæ…®åƒ¹æ ¼
assert result["scenario"] == "study"
questions = result["questions"]
first_few_features = [q["feature_id"] for q in questions[:3]]
assert "price" in first_few_features  # åƒ¹æ ¼æ‡‰è©²åœ¨å‰å¹¾å€‹å•é¡Œä¸­
```

**ç¯„ä¾‹ 5: é…ç½®æ–‡ä»¶éŒ¯èª¤è™•ç†**
```python
# æ¨¡æ“¬é…ç½®æ–‡ä»¶æå£æˆ–ä¸å­˜åœ¨çš„æƒ…æ³
service._nb_features_config = None  # æ¸…é™¤å¿«å–

# å¦‚æœé…ç½®è¼‰å…¥å¤±æ•—ï¼Œæ‡‰è©²è¿”å›éŒ¯èª¤
result = service.get_all_questions("test query")
if "error" in result:
    assert "ç„¡æ³•è¼‰å…¥å•é¡Œé…ç½®" in result["error"]
```

#### ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚è©³è§£

**èˆ‡ `nb_features.json` çš„æ·±åº¦æ•´åˆ:**

**é…ç½®æ–‡ä»¶çµæ§‹ç¯„ä¾‹:**
```json
{
  "nb_features": {
    "cpu": {
      "feature_id": "cpu",
      "name": "è™•ç†å™¨(CPU)åå¥½", 
      "question_template": "è«‹å•æ‚¨å°è™•ç†å™¨(CPU)æœ‰ä»€éº¼åå¥½å—ï¼Ÿ",
      "options": [
        {
          "option_id": "high_performance",
          "label": "ğŸš€ é«˜æ•ˆèƒ½è™•ç†å™¨",
          "description": "é©åˆéŠæˆ²ã€å‰µä½œã€å¤šå·¥è™•ç†",
          "db_filter": {"cpu_tier": "high"}
        }
      ]
    }
  },
  "feature_priorities": {
    "gaming": ["gpu", "cpu", "memory", "storage", "price"],
    "business": ["weight", "cpu", "price", "size", "memory"]
  }
}
```

**æ•¸æ“šæµå‘åˆ†æ:**
1. **é…ç½®è¼‰å…¥**: ç³»çµ±å•Ÿå‹•æ™‚è¼‰å…¥å®Œæ•´é…ç½®
2. **å ´æ™¯åŒ¹é…**: æ ¹æ“šç”¨æˆ¶æŸ¥è©¢ç¢ºå®šå ´æ™¯é¡å‹
3. **å„ªå…ˆç´šæ‡‰ç”¨**: ä½¿ç”¨å ´æ™¯å°æ‡‰çš„ç‰¹æ€§å„ªå…ˆé †åº
4. **å•é¡Œç”Ÿæˆ**: æŒ‰å„ªå…ˆç´šé †åºç”Ÿæˆçµæ§‹åŒ–å•é¡Œ
5. **é¸é …è™•ç†**: æå–æ¯å€‹ç‰¹æ€§çš„å¯é¸é …å’Œæè¿°

#### ğŸ’¡ é–‹ç™¼è€…æŒ‡å—

**å¦‚ä½•æ“´å±•å•å·åŠŸèƒ½:**

1. **æ·»åŠ æ–°çš„å ´æ™¯é¡å‹:**
```json
{
  "feature_priorities": {
    "content_creation": ["gpu", "cpu", "memory", "storage", "size", "price", "weight"],
    "data_analysis": ["cpu", "memory", "storage", "gpu", "price", "weight", "size"]
  }
}
```

2. **å‹•æ…‹å•é¡Œç”Ÿæˆ:**
```python
def get_adaptive_questions(self, query: str, user_profile: dict = None):
    # æ ¹æ“šç”¨æˆ¶æ­·å²åå¥½èª¿æ•´å•é¡Œ
    if user_profile:
        # è·³éç”¨æˆ¶å·²æœ‰æ˜ç¢ºåå¥½çš„å•é¡Œ
        skip_features = [f for f, pref in user_profile.items() if pref["confidence"] > 0.8]
        
        # é‡å°ä¸ç¢ºå®šçš„åå¥½å¢åŠ è©³ç´°å•é¡Œ
        detailed_features = [f for f, pref in user_profile.items() if pref["confidence"] < 0.5]
```

3. **æ¢ä»¶å¼å•é¡Œæµç¨‹:**
```python
def get_conditional_questions(self, previous_answers: dict):
    questions = []
    
    # å¦‚æœç”¨æˆ¶é¸æ“‡é«˜æ•ˆèƒ½CPUï¼Œå‰‡è©¢å•æ›´è©³ç´°çš„GPUéœ€æ±‚
    if previous_answers.get("cpu") == "high_performance":
        questions.append(self._generate_detailed_gpu_question())
    
    # å¦‚æœç”¨æˆ¶é‡è¦–ä¾¿æ”œæ€§ï¼Œå‰‡è©¢å•å…·é«”çš„é‡é‡è¦æ±‚
    if previous_answers.get("weight") == "ultralight":
        questions.append(self._generate_specific_weight_question())
    
    return questions
```

**å€‹æ€§åŒ–å„ªåŒ–ç­–ç•¥:**
- ğŸ¯ **ç”¨æˆ¶ç•«åƒ**: æ ¹æ“šæ­·å²æŸ¥è©¢å»ºç«‹ç”¨æˆ¶åå¥½æ¨¡å‹
- ğŸ¯ **æ™ºèƒ½è·³é**: è‡ªå‹•è·³éç”¨æˆ¶å·²æœ‰æ˜ç¢ºç­”æ¡ˆçš„å•é¡Œ
- ğŸ¯ **å‹•æ…‹èª¿æ•´**: æ ¹æ“šå‰é¢çš„å›ç­”èª¿æ•´å¾ŒçºŒå•é¡Œçš„å…§å®¹
- ğŸ¯ **å¤šèªè¨€æ”¯æ´**: æ”¯æ´ä¸åŒèªè¨€çš„å•é¡Œå’Œé¸é …

**æ¸¬è©¦ç­–ç•¥:**
- ğŸ§ª **å ´æ™¯è¦†è“‹æ¸¬è©¦**: ç¢ºä¿æ‰€æœ‰å ´æ™¯éƒ½èƒ½æ­£ç¢ºç”Ÿæˆå•é¡Œ
- ğŸ§ª **å•é¡Œå®Œæ•´æ€§æ¸¬è©¦**: é©—è­‰ç”Ÿæˆçš„å•é¡Œçµæ§‹å®Œæ•´
- ğŸ§ª **å„ªå…ˆç´šæ¸¬è©¦**: ç¢ºèªä¸åŒå ´æ™¯çš„å•é¡Œé †åºç¬¦åˆé æœŸ
- ğŸ§ª **éŒ¯èª¤è™•ç†æ¸¬è©¦**: æ¸¬è©¦é…ç½®æ–‡ä»¶ç•°å¸¸æƒ…æ³çš„è™•ç†

---

## ğŸ”— é…ç½®æ–‡ä»¶é—œä¿‚åœ–è§£

### JSON é…ç½®æ–‡ä»¶ä½¿ç”¨çŸ©é™£

| å‡½æ•¸åç¨± | entity_patterns.json | query_keywords.json | nb_features.json | chats.json |
|---------|:-------------------:|:------------------:|:---------------:|:----------:|
| `_parse_query_intent()` | âŒ | âœ… | âŒ | âŒ |
| `_check_query_contains_modelname()` | âœ… | âŒ | âŒ | âŒ |
| `_check_query_contains_modeltype()` | âœ… | âŒ | âŒ | âŒ |
| `get_all_questions()` | âŒ | âŒ | âœ… | âŒ |
| `process_multichat_response()` | âŒ | âŒ | âœ… | âœ… |
| `_load_intent_keywords()` | âŒ | âœ… | âŒ | âŒ |
| `chat_stream()` | âœ… | âœ… | âœ… | âŒ |

### é…ç½®æ–‡ä»¶è©³ç´°èªªæ˜

#### ğŸ“‹ `entity_patterns.json` - å¯¦é«”è­˜åˆ¥è¦å‰‡åº«
```json
{
  "entity_patterns": {
    "MODEL_NAME": {
      "patterns": ["[A-Z]{2,3}\\d{3}(?:-[A-Z]+)?"],
      "examples": ["AG958", "APX958", "AB819-S"]
    },
    "MODEL_TYPE": {
      "patterns": ["(?:819|839|958|960)"],
      "examples": ["819", "958"]
    }
  }
}
```

**ä½¿ç”¨å‡½æ•¸:**
- `_check_query_contains_modelname()`: ä½¿ç”¨ MODEL_NAME æ¨¡å¼è­˜åˆ¥ç­†é›»å‹è™Ÿ
- `_check_query_contains_modeltype()`: ä½¿ç”¨ MODEL_TYPE æ¨¡å¼è­˜åˆ¥ç³»åˆ—è™Ÿ

#### ğŸ” `query_keywords.json` - æŸ¥è©¢æ„åœ–é—œéµå­—åº«
```json
{
  "intent_keywords": {
    "cpu": {
      "keywords": ["cpu", "è™•ç†å™¨", "processor"],
      "description": "CPUç›¸é—œæŸ¥è©¢"
    },
    "comparison": {
      "keywords": ["æ¯”è¼ƒ", "compare", "å·®ç•°"],
      "description": "æ¯”è¼ƒç›¸é—œæŸ¥è©¢"
    }
  }
}
```

**ä½¿ç”¨å‡½æ•¸:**
- `_parse_query_intent()`: ä¸»è¦ä½¿ç”¨è€…ï¼Œç”¨æ–¼æ„åœ–åˆ†é¡
- `_load_intent_keywords()`: è¼‰å…¥å’Œç®¡ç†é—œéµå­—é…ç½®

#### ğŸ“ `nb_features.json` - å¤šè¼ªå°è©±é…ç½®åº«
```json
{
  "nb_features": {
    "cpu": {
      "question_template": "è«‹å•æ‚¨å°è™•ç†å™¨æœ‰ä»€éº¼åå¥½ï¼Ÿ",
      "options": [
        {
          "option_id": "high_performance",
          "label": "é«˜æ•ˆèƒ½è™•ç†å™¨",
          "description": "é©åˆéŠæˆ²ã€å‰µä½œ"
        }
      ]
    }
  },
  "feature_priorities": {
    "gaming": ["gpu", "cpu", "memory"],
    "business": ["weight", "price", "cpu"]
  }
}
```

**ä½¿ç”¨å‡½æ•¸:**
- `get_all_questions()`: ä¸»è¦ä½¿ç”¨è€…ï¼Œç”Ÿæˆå•å·çµæ§‹
- `process_multichat_response()`: è™•ç†ç”¨æˆ¶çš„å•å·å›ç­”

### æ•¸æ“šæµå‘é—œä¿‚åœ–

```mermaid
graph TD
    A[ç”¨æˆ¶æŸ¥è©¢] --> B[chat_stream]
    B --> C[_parse_query_intent]
    C --> D[query_keywords.json]
    
    B --> E[_check_query_contains_modelname]
    E --> F[entity_patterns.json]
    
    B --> G[å¤šè¼ªå°è©±æª¢æŸ¥]
    G --> H[get_all_questions]
    H --> I[nb_features.json]
    
    B --> J[LLMè™•ç†]
    J --> K[å‰ç«¯æ¸²æŸ“]
```

### é…ç½®æ–‡ä»¶ç¶­è­·æŒ‡å—

#### ğŸ”§ å¦‚ä½•æ·»åŠ æ–°çš„æ„åœ–é¡å‹
1. åœ¨ `query_keywords.json` ä¸­æ·»åŠ æ–°çš„æ„åœ–åˆ†é¡ï¼š
```json
{
  "intent_keywords": {
    "gaming": {
      "keywords": ["éŠæˆ²", "gaming", "é›»ç«¶", "fps"],
      "description": "éŠæˆ²æ•ˆèƒ½ç›¸é—œæŸ¥è©¢"
    }
  }
}
```

2. åœ¨ç›¸é—œå‡½æ•¸ä¸­æ·»åŠ è™•ç†é‚è¼¯ï¼š
```python
def _parse_query_intent(self, query: str):
    # ... ç¾æœ‰é‚è¼¯
    if result["intent"] == "gaming":
        # ç‰¹æ®Šçš„éŠæˆ²æŸ¥è©¢è™•ç†é‚è¼¯
        pass
```

#### ğŸ”§ å¦‚ä½•æ·»åŠ æ–°çš„ç­†é›»å‹è™Ÿè­˜åˆ¥
1. æ›´æ–° `entity_patterns.json`ï¼š
```json
{
  "entity_patterns": {
    "MODEL_NAME": {
      "patterns": [
        "[A-Z]{2,3}\\d{3}(?:-[A-Z]+)?",
        "æ–°çš„å‹è™Ÿæ ¼å¼æ­£å‰‡è¡¨é”å¼"
      ]
    }
  }
}
```

2. æ›´æ–°æ•¸æ“šåº«ä¸­çš„ `AVAILABLE_MODELNAMES` åˆ—è¡¨

#### ğŸ”§ å¦‚ä½•æ·»åŠ æ–°çš„å¤šè¼ªå°è©±ç‰¹æ€§
1. åœ¨ `nb_features.json` ä¸­æ·»åŠ æ–°ç‰¹æ€§ï¼š
```json
{
  "nb_features": {
    "display": {
      "feature_id": "display",
      "name": "è¢å¹•åå¥½",
      "question_template": "è«‹å•æ‚¨å°è¢å¹•æœ‰ä»€éº¼è¦æ±‚ï¼Ÿ",
      "options": [
        {
          "option_id": "large_screen",
          "label": "å¤§è¢å¹•å„ªå…ˆ",
          "description": "17å‹ä»¥ä¸Šè¢å¹•"
        }
      ]
    }
  }
}
```

2. åœ¨å„å€‹å ´æ™¯çš„å„ªå…ˆç´šä¸­æ·»åŠ é€™å€‹ç‰¹æ€§ï¼š
```json
{
  "feature_priorities": {
    "gaming": ["gpu", "cpu", "display", "memory"],
    "business": ["weight", "display", "cpu", "price"]
  }
}
```

---

## ğŸ“ˆ ç³»çµ±å”ä½œæµç¨‹åœ–

### å®Œæ•´æŸ¥è©¢è™•ç†æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ¶
    participant F as å‰ç«¯
    participant API as sales_routes
    participant S as SalesAssistantService  
    participant DB as æ•¸æ“šåº«
    participant LLM as LLMæœå‹™
    
    U->>F: è¼¸å…¥æŸ¥è©¢
    F->>API: POST /chat-stream
    API->>S: chat_stream(query)
    
    S->>S: _parse_query_intent()
    Note over S: ä½¿ç”¨ query_keywords.json
    
    alt æ¨¡ç³ŠæŸ¥è©¢
        S->>S: get_all_questions()
        Note over S: ä½¿ç”¨ nb_features.json
        S->>API: è¿”å›å•å·æ•¸æ“š
    else å…·é«”æŸ¥è©¢
        S->>S: _get_data_by_query_type()
        S->>DB: æŸ¥è©¢ç­†é›»æ•¸æ“š
        DB->>S: è¿”å›è¦æ ¼æ•¸æ“š
        
        S->>LLM: èª¿ç”¨æ¨ç†
        LLM->>S: è¿”å›åˆ†æçµæœ
        
        S->>S: _process_llm_response()
        S->>S: _create_beautiful_markdown_table()
        S->>API: è¿”å›æ ¼å¼åŒ–çµæœ
    end
    
    API->>F: SSE æ•¸æ“šæµ
    F->>U: æ¸²æŸ“çµæœ
```

### å¤šè¼ªå°è©±è™•ç†æµç¨‹

```mermaid
stateDiagram-v2
    [*] --> æ„åœ–æª¢æ¸¬
    æ„åœ–æª¢æ¸¬ --> æ¨¡ç³ŠæŸ¥è©¢: æª¢æ¸¬åˆ°æ¨¡ç³Šéœ€æ±‚
    æ„åœ–æª¢æ¸¬ --> ç›´æ¥æŸ¥è©¢: å…·é«”æŸ¥è©¢
    
    æ¨¡ç³ŠæŸ¥è©¢ --> å ´æ™¯è­˜åˆ¥
    å ´æ™¯è­˜åˆ¥ --> å•å·ç”Ÿæˆ: ä½¿ç”¨ nb_features.json
    å•å·ç”Ÿæˆ --> ç­‰å¾…å›ç­”
    
    ç­‰å¾…å›ç­” --> æ”¶é›†åå¥½: ç”¨æˆ¶å¡«å¯«å•å·
    æ”¶é›†åå¥½ --> åŸ·è¡ŒæŸ¥è©¢: process_all_questions_response
    
    ç›´æ¥æŸ¥è©¢ --> æ•¸æ“šæª¢ç´¢
    åŸ·è¡ŒæŸ¥è©¢ --> æ•¸æ“šæª¢ç´¢
    æ•¸æ“šæª¢ç´¢ --> LLMæ¨ç†
    LLMæ¨ç† --> çµæœè¿”å›
    çµæœè¿”å› --> [*]
```

---

## ğŸ“ ç¸½çµ

æœ¬æ–‡æª”è©³ç´°è§£æäº† `SalesAssistantService` ä¸­æ¯å€‹æ ¸å¿ƒå‡½æ•¸çš„å¯¦ä½œç´°ç¯€ï¼ŒåŒ…æ‹¬ï¼š

### ğŸ¯ æ ¸å¿ƒäº®é»
1. **ç³»çµ±åŒ–çš„æ¶æ§‹è¨­è¨ˆ** - æ¯å€‹å‡½æ•¸éƒ½æœ‰æ˜ç¢ºçš„è·è²¬å’Œéš±å–»èº«ä»½
2. **å®Œå–„çš„éŒ¯èª¤è™•ç†** - å¤šå±¤æ¬¡çš„ç•°å¸¸è™•ç†å’Œå‚™æ´æ©Ÿåˆ¶  
3. **éˆæ´»çš„é…ç½®ç®¡ç†** - æ”¯æ´å‹•æ…‹è¼‰å…¥å’Œç†±æ›´æ–°é…ç½®æ–‡ä»¶
4. **æ™ºèƒ½çš„æ„åœ–è­˜åˆ¥** - çµåˆé—œéµå­—åŒ¹é…å’Œæ¨¡å¼è­˜åˆ¥çš„å¤šé‡ç­–ç•¥
5. **å„ªé›…çš„æ•¸æ“šè½‰æ›** - æ”¯æ´å¤šç¨®æ•¸æ“šæ ¼å¼çš„è‡ªå‹•è½‰æ›å’Œç¾åŒ–

### ğŸ”§ é–‹ç™¼æŒ‡å°
- **æ“´å±•æ€§** - æ¯å€‹å‡½æ•¸éƒ½æä¾›äº†æ“´å±•å»ºè­°å’Œç¯„ä¾‹ä»£ç¢¼
- **å¯ç¶­è­·æ€§** - è©³ç´°çš„è¨»è§£å’Œæ¸…æ™°çš„é‚è¼¯æµç¨‹
- **å¯æ¸¬è©¦æ€§** - è±å¯Œçš„æ¸¬è©¦ç¯„ä¾‹å’Œé‚Šç•Œæƒ…æ³è™•ç†
- **æ•ˆèƒ½å„ªåŒ–** - å…·é«”çš„æ•ˆèƒ½æ”¹é€²å»ºè­°å’Œå¯¦ä½œç­–ç•¥

### ğŸ¨ è¨­è¨ˆå“²å­¸
é€šéç”Ÿå‹•çš„éš±å–»å’Œå¯¦éš›ç¯„ä¾‹ï¼Œé€™å€‹ç³»çµ±ä¸åƒ…åƒ…æ˜¯ä»£ç¢¼çš„é›†åˆï¼Œæ›´åƒæ˜¯ä¸€å€‹æœ‰æ©Ÿçš„æœå‹™ç”Ÿæ…‹ç³»çµ±ï¼Œæ¯å€‹çµ„ä»¶éƒ½æœ‰è‡ªå·±çš„å€‹æ€§å’Œè·è²¬ï¼Œå…±åŒå”ä½œç‚ºç”¨æˆ¶æä¾›å„ªè³ªçš„ç­†é›»è«®è©¢é«”é©—ã€‚

---

*æ–‡æª”ç‰ˆæœ¬: v1.0*  
*æœ€å¾Œæ›´æ–°: 2025å¹´1æœˆ*  
*ä½œè€…: SalesRAG é–‹ç™¼åœ˜éšŠ*