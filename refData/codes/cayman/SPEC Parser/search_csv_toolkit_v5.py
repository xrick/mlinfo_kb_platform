
import csv
import json
import argparse

#add: 20250722 cayman
def convert_xlsx_to_csv_if_needed(file_path):

    if file_path.lower().endswith(".csv"):

        return file_path

    elif file_path.lower().endswith(".xlsx"):

        print(f"ğŸ” åµæ¸¬åˆ° XLSX æª”æ¡ˆï¼Œæ­£åœ¨è½‰æ›ç‚º CSVï¼š{file_path}")

        df = pd.read_excel(file_path, sheet_name=0, header=None)

        temp_csv_path = os.path.join(tempfile.gettempdir(), "_converted_temp.csv")

        df.to_csv(temp_csv_path, index=False, header=False, encoding="utf-8-sig")

        print(f"âœ… å·²è½‰æ›ç‚ºæš«å­˜ CSVï¼š{temp_csv_path}")

        return temp_csv_path

    else:

        raise ValueError("âŒ åƒ…æ”¯æ´ .csv æˆ– .xlsx æª”æ¡ˆï¼")

def load_csv(file_path):
    with open(file_path, mode='r', encoding='utf-8-sig') as f:
        return list(csv.reader(f))

def load_rules(json_path):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)

def collect_results(reader, rules, model_count):
    result_rows = [[] for _ in range(model_count)]

    for rule_index, rule in enumerate(rules):
        keywords = rule.get("keywords", [])
        logic = rule.get("logic", "OR").upper()
        rowspan = rule.get("rowspan", 1)
        column_name = rule.get("column_name", f"æ¬„ä½{rule_index+1}")

        matched_blocks = []

        for i, row in enumerate(reader):
            if logic == "AND":
                match = True
                for kw in keywords:
                    if not any(kw.lower() in str(cell).lower() for cell in row):
                        match = False
                        break
            else:
                match = False
                for kw in keywords:
                    if any(kw.lower() in str(cell).lower() for cell in row):
                        match = True
                        break

            if match:
                block = reader[i:i + rowspan]
                matched_blocks.append((i, block))

        if len(matched_blocks) == 0:
            print(f"âš ï¸ è¦å‰‡ {rule_index+1} - {column_name}: æ‰¾ä¸åˆ°é—œéµå­— {keywords}ï¼Œå…¨æ¬„å¡«ç©ºç™½")
            for idx in range(model_count):
                result_rows[idx].append("")
        else:
            if len(matched_blocks) > 1:
                print(f"âš ï¸ è­¦å‘Šï¼šè¦å‰‡ {rule_index+1} - {column_name} æ‰¾åˆ°è¶…éä¸€å€‹åŒ¹é…ï¼ˆå…± {len(matched_blocks)} å€‹ï¼‰ï¼Œåƒ…ä½¿ç”¨ç¬¬ä¸€ç­†ï¼")
            first_index, block = matched_blocks[0]
            print(f"ğŸ” è¦å‰‡ {rule_index+1} - {column_name}: æ‰¾åˆ°é—œéµå­— {keywords} æ–¼ç¬¬ {first_index+1} è¡Œ")

            for idx in range(model_count):
                col_index = 2 + idx
                if all(col_index < len(row) for row in block):
                    lines = []
                    for r in block:
                        value = r[col_index].strip()
                        prefix_label = r[1].strip() if len(r) > 1 else ""
                        if prefix_label:
                            lines.append(f"{prefix_label}: {value}")
                        else:
                            lines.append(value)
                    result = "\n".join(lines).strip()
                    result_rows[idx].append(result)
                    print(f"  â†’ æ©Ÿç¨®{idx+1}: {result}")
                else:
                    result_rows[idx].append("")
                    print(f"  â†’ æ©Ÿç¨®{idx+1}: âš ï¸è­¦å‘Šï¼šè©²æ©Ÿç¨®æ­¤è™•ç„¡è³‡æ–™")

    return result_rows

def write_csv(output_path, result_rows, headers, model_type):
    headers = ["modeltype"] + headers
    with open(output_path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        for row in result_rows:
            writer.writerow([model_type] + row)
    print(f"âœ… å·²è¼¸å‡ºè‡³ï¼š{output_path}")

def main():
    parser = argparse.ArgumentParser(description="æ ¹æ“š JSON è¦å‰‡æœå°‹ CSV ä¸¦è½‰ç‚ºæ¯æ©Ÿç¨®ä¸€åˆ—æ ¼å¼ï¼ˆv4 + prefix æ¯åˆ—è®€å–ï¼‰")
    parser.add_argument("csv_path", help="è¼¸å…¥CSV")
    parser.add_argument("json_path", help="è¦å‰‡JSON")
    parser.add_argument("--model_count", type=int, required=True, help="å¹¾å€‹æ©Ÿç¨®")
    parser.add_argument("--model_type", type=str, required=True, help="å…±ç”¨çš„ model type å­—ä¸²")
    parser.add_argument("--output_csv", required=True, help="è¼¸å‡ºCSVæª”å")

    args = parser.parse_args()

    csv_path = convert_xlsx_to_csv_if_needed(args.csv_path) # add:20250722 Rick
    reader = load_csv(args.csv_path)
    rules = load_rules(args.json_path)
    results = collect_results(reader, rules, args.model_count)

    headers = [
        rule.get("column_name").strip() if rule.get("column_name") and rule.get("column_name").strip() != "" else f"æ¬„ä½{i+1}"
        for i, rule in enumerate(rules)
    ]
    write_csv(args.output_csv, results, headers, args.model_type)

if __name__ == "__main__":
    main()
